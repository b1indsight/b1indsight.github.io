[{"id":0,"href":"/posts/","title":"Posts","section":"","content":" Get Home "},{"id":1,"href":"/posts/normal_accident/","title":"正常事故","section":"Posts","content":"在查尔斯·佩罗的《高风险系统与正常事故》（后面简称《正常事故》）这本书中，作者认为一些高风险技术的特征表明，不管常规安全措施如何，一种事故的发生是不可避免甚至是正常的。本期的主要内容便是自三里岛事故的部分介绍开始，对正常事故的一些讨论。\n三里岛事故 # 让我们首先从1979年的三里岛核电厂事故看起，这指的是1979年3月28日三里岛核电站发生的一次部分堆芯熔毁事故，场内污染清理从1979年8月开始，直到1993年12月结束。在查尔斯·佩罗写作《正常事故》这本书的时间点看起，三里岛事故是迄今为止最严重的核电厂事故，而相对于现在来说，依然是美国商用核电历史上最严重的事故。首先介绍一些相关系统的信息。\n机组的结构简图如下：\n可以转化为下图的示意图：\n系统简述 # 反应堆正常工作时，初级冷却系统的水始终保持高温高压流经堆芯，经过蒸汽发生器淋到次级冷却系统的水管上，次级系统的水转化为蒸汽驱动涡轮发电机。\n初级冷却系统涉及以下一些自动安全装置：\n自控减压阀在堆芯压力过高时放出堆芯的水来减少压力，但是自控减压阀开启时间不宜过长，因为当排出的水过多压力太低，高温的水将变成蒸汽泡阻塞初级冷却系统，会阻碍冷却水流动，造成部分位置过热并再次启动裂变反应。 为了防止压力降低之后高温水变为蒸汽，两个反应水冷却泵会自动启动向初级冷却系统注水降温。 高压注入泵向堆芯注入高压冷却水降低温度。但是高压注入泵注入的高压冷水可能使堆芯产生裂痕，为防止高压注入泵的副作用，高压注入泵和堆芯之间通过缓压器来减少压力。缓压器是一个下半部为水上半部为蒸汽的罐子，当注入的水过多，缓压器会被注满，可能导致冷却水管破裂，造成失水事故，严重的情况会导致堆芯熔融。 次级冷却系统保持高压，次级冷却系统的水与初级冷却系统保持隔离，而且鉴于涡轮机叶片十分精细，所以必须保持纯净，因此有一个冷凝水净化系统来清除微粒。紧急给水泵在主供水泵停机时将紧急储水箱的水抽出来，维持次级冷却系统工作，两个管道阀门均含有指示灯。 事故发生 # 冷凝水净化器在二号堆启用几个月后坏过3次，而3月28日凌晨4点汽轮机不转了，事后分析是由于净化器封焊口漏出大约一杯水量的水。水的湿气进入了仪器控制系统，结果导致水泵停止工作，冷水不再流动，于是汽轮机随后停止。\n紧急给水泵随后试图供水，用来补充次级供水系统的水，但是两天前检修后，管道阀门全是关闭位置，操作者知道紧急给水泵在运行，但是并不知道管道不通。这两个供水指示灯虽然指示阀门关闭，但是其中一个灯被挂在开关上的修理标签遮住了，鉴于操作者没有想到阀门是关的，所以并没有立刻去看阀门指示灯，而在八分钟之后才发现阀门没打开，但此时已经造成一部分危害。\n进入事故状态13秒，次级冷却系统缺水之后，蒸汽发生器很快烧干，初级冷却系统温度居高不下，堆芯无法冷却，因此反应堆急停，但是衰减的放射性物资仍然还在产生热量。高压触发自控减压阀，放出堆芯的水到缓压器，因为自控减压阀不能开启过长，并且堆芯压力迅速下降，于是操作者决定关闭自控减压阀，但是由于出现一些故障，导致自控减压阀没有完全关闭，冷却水仍然在漏出。鉴于减压阀在之前出现过故障，前不久为此加了一个指示灯，以便操作者观察是否复位，但是指示灯在阀门收到关闭脉冲时标志阀门关闭，而不是阀门事实上关闭，于是操作者认为自控减压阀一切正常。\n在进入事故状态后的两三分钟内，水不断通过自控减压阀漏出，但是堆芯温度并没有下降，这样过热的水即将变为蒸汽，于是反应水冷却泵向堆芯注水，此时由于未知的原因造成了冷却水稳定的假象，一切似乎有所控制。\n进入事故状态的两分钟后，冷却水并未稳定，此时堆芯仍然在失水，初级冷却系统中压力剧降，高压注入泵自动启动，因为之上提过的高压注入泵的原因，高压注入泵在注入2分钟之后就被操作员手动降低了注入速度。高压注入泵启动之后，一个表指出堆芯压力正在减少，而另一个指示表显示缓压器压力正在升高。此时的状况使操作者迷惑不解，一般情况下缓压器和堆芯压力升降趋势应该一致，此时选择相信哪一个指示表造成了一个两难问题，而反应堆的生产厂家和用户都很注意在培训时让操作者树立缓压器不能注满的观念，此时操作者选择更加熟悉的高压注入和缓压器的相互关系，急剧降低了高压注入速度。\n二号堆的设计造成无法直接测量堆芯水面高度，但是此时还有三个读数可能了解到发生失水事故，一个是污水池压力，水经由自控减压阀-\u0026gt;缓压器被排放到污水池，污水池压力增加。但是设计者不认为这是一个重要指标，指示灯布置在七英尺高控制板背面靠近底部的位置，在没有人意识到发生失水事故的情况下，查看度数是个费力不讨好的动作，所以谁也不乐意去看。另一是污水池温度，污水池接受堆芯内的高温水，导致温度升高。但是有一个自控减压阀已经漏水好几个星期，冷却水总是漏出，导致污水池温度总是偏高。剩余一个读数是堆芯压力，但是正如之前所说，操作员相信堆芯压力指示表有问题，因为它与缓压器压力读数相矛盾。\n在进入事故状态四五分钟后，由于初级冷却系统失水，反应水冷却泵没有足够水流过，开始剧烈颤动，声音大到控制室都可以听到。操作者们紧急开会之后，鉴于水泵可能顶不住如此剧烈的颤动，于是决定紧急关泵。\n在进入事故状态2小时20分钟之后，终于有人意识到自控减压阀出了问题，发现阀门并没有复位，于是紧急关闭了一个截止阀。在事后听证会上，一位操作者作证这这个措施是忙乱中瞎碰运气，幸好这个措施及时阻止了堆芯完全熔融。\n进入事故状态33小时，控制室的人听到了轻微爆炸声，安全壳压力计度数突然跳到了安全壳设计极限的一半。这是由于堆芯燃料棒的锆合金外壳与水蒸气发生反应放出氢气，形成氢气泡，氢气可能从堆罩中经自控减压阀进入安全壳，造成氢气爆炸。在场的某人知道发生了氢气爆炸，于是让另一名操作者不要再启动一台出故障的水泵（水泵马达启动时会产生火花）。\n正常事故 # 在大多数高风险系统中，由于系统的一些特性导致事故是不可避免的，以至于产生事故被看作是自然发生的，我们把这些事故叫做正常事故。三里岛事故就是一个典型的正常事故。\n正常事故有几个典型的特征：系统中的各组件作用是预料外的，而且在紧要关头是不可理解的；由于系统特征，事故的破坏速度显著超过维护者抢救的速度，破坏范围不断扩大，而事故层出不穷。\n考虑第一个特征，三里岛事故可以看作是由一些故障复合而成的，分别是1.净化器漏水，2.紧急给水泵阀门被误关闭，3.自控减压阀无法复位，4.自控减压阀的指示灯失灵。这四个故障如果单独发生，仅仅是连事件都算不上的小问题，如果提前得知这些故障，也无从想出会产生这样的事故，因此可以把这个事故划为系统事故，即多重故障以不可预期的方式相互作用。在操作者的视角观察，净化器漏水导致汽轮机停机几乎预想不到；次级冷却系统故障导致初级冷却系统烧干也很难立刻联想到，或者说等到联想到这个问题，已经太迟了；缓压器与堆芯由管道连接，但是缓压器压力上升而堆芯压力迅速下降，此时也造成了疑惑，鉴于之前从未发生失水事故，因此操作者能全面接受堆芯压力指示而无视手册上防止缓压器注满的警告，这一要求也显得强人所难；堆芯发生锆-水反应导致氢气爆炸同样是不可理解的。这些系统的运行路径均是超过设计的生产路径的，而产生的警告信号必须要能与思维模式吻合才能使操作者理解并产生警告效果。更不必说警告信号也同样是故障的。\n部分原因在于，这种人机系统中的相互作用确实 是看不见的(这里，“看不见的”取其本义) , 另一部分原因在于，即使能看见这种相互作用，人们也不相信。\n第二个特征就很好理解，事故破坏范围迅速扩大，在13秒的时间内蒸汽发生器便烧干了，堆芯自控减压阀启动，如果想对它做出什么处理的话，必须要求操作者理解次级冷却系统的故障造成了初级冷却系统的事故，这一切都要在13秒内进行。随后2，3分钟后两难问题出现，缓压器压力到达高点且在继续上升，堆芯压力却在下降，操作者需要在缓压器注满前紧急减少高压注水的速度（操作手册中如此写着），或是相信堆芯压力下降，冒着可能的（他们考虑中的）失水风险继续注水。事故状态四五分钟后，操作室又听到输运泵的震动，事故层出不穷。可以看到事故恶化的速度远超操作员理解的速度，操作员不得不在两到三分钟之内理解新的险情的运作方式才有可能做出正确决定，而这是显然不可能的。\n而产生正常事故这些特征的原因，主要在于系统组成的特征，查尔斯·佩罗在《正常事故》中提出了两个衡量标准，其一可以被称为复杂度，坐标轴的两端是线性系统-复杂系统。线性系统划分各个生产阶段，每个生产阶段在空间上分离,生产阶段内及生产阶段间主要保持序贯式的联系，系统中的反馈极少，而且反馈信息更多是直接的。复杂系统中每个生产阶段的组件相互接近，产生许多共模联系，具有不熟悉或预想不到的反馈回路，指标和控制参数之间相互作用，系统的状况需要从反馈信息中推断而不是直接获得，另外有一些完全没搞清的工艺过程。\n另一系统衡量标准是系统的配合特性，坐标轴的两端是紧配合-松配合，在紧配合的系统中工序的工艺流程相关性很高且难以拖延，同时工序恒定而通常环节设计为只有一种方式到达目标，另外紧配合系统具有很少的松弛环节，某一环节出错难以使用其它资源临时替代。而松配合系统则与之相反。在紧配合系统这些特征之外，我认为可以另一导致紧配合系统的特点在于系统中上一环节组件异常之后影响到下一环节所需的时间很短（特别是相对于操作者或决策者理解现状的时间），这可能会导致操作者无法做出正确应对，更糟糕的情况下会扩大事故影响范围。\n系统的复杂度和配合特性可以看作是两个相互独立的特征范围，在这两个坐标轴构成的坐标系中，具有紧配合的复杂系统这样的结构导致出现事故是不可避免的，甚至是正常的。\n一些附属的风险系统 # 错误引致系统 # 错误引致系统的特殊之处在于错误是由系统各组元的组合方式造成的，对组元的改进或变化，不是由其他部分不予合作而不行，或是其他部分将得到强烈表现而使变化毫无意义。《正常事故》中认为水上运输是一个错误引致系统，技术手段的进步促进了生产，但也促进了事故的发生。另外同样有利于巩固这个结构。\n自激系统 # 核武的侦测系统似乎是这一种系统，侦测方需要从环境噪音中正确判断信号，而鉴于后果严重，系统不仅需要防止故障，而且要杜绝故障被掩盖的可能性。攻击方则要使信号更加贴近环境噪音，缩短侦测者的反应时间，对侦测者施加破坏以造成故障。这样侦测系统的复杂度和配合特性的提升是有意造成且自我激发形成正反馈回路的。\n最后谈一些错误认知。在几乎所有的事故回顾中，严重疏忽和无能都是存在的，不安全的操作，偷工减料的设备，无视安全规范的设计层出不穷，一旦发生事故，人们总会找到容易发生重大事故的主要原因。在这里必须说明的地方在于，可以说组织无能是组织的正常状态，在生产压力下疏忽和错误也是不可避免的，即使出现一些错误征兆，人们也倾向于忽略它或是将它解释为熟悉的状态，几乎不可能为了事故隐患而每次停机，然而回顾往事时总能找到这些警告信号。\n"},{"id":2,"href":"/posts/super_and_mro_algorithm/","title":"Super函数和mro算法","section":"Posts","content":"super()作为在python中常被使用到的一个方法而言，具有一些有趣的特性，本文可以看作super()的一个考古，主要包括以下几个部分：\nsuper()的定义和用法 构造__mro__属性中类继承顺序线性化的算法 提供了一个super()的简单实现 super()的定义和用法 # 首先提供一个super(type, object-or-type)的定义：\n在object-or-type中__mro__指定的搜索路径中,返回type后的下一个类对象的代理。\n例如object-or-type的__mro__指定的查找路径为D-\u0026gt;B-\u0026gt;C-\u0026gt;A-\u0026gt;object, 并且type的值为B，则super(type, object-or-type)将返回路径中B的下一个类C的代理。\n关于未绑定的一个问题 # super()的两个参数都是可选参数，如果省略第二个参数，则返回一个未绑定的超类对象。在这个角度中，super()返回的代理对象与super()的第二个参数绑定。\n这一点可以用以下的代码测试：先构造两个类A，B，并初始化\nclass A(): def __init__(self): self.s = \u0026#39;a\u0026#39; def method(self): print(\u0026#39;obj A\u0026#39;) return self.s def __repr__(self): return \u0026#39;A: {}\u0026#39;.format(self.__class__.__name__) class B(A): s = \u0026#39;B\u0026#39; def __init__(self): super().__init__() self.s = \u0026#39;b\u0026#39; def method(self): print(\u0026#39;obj B\u0026#39;) super().method() return self.s def __repr__(self): return \u0026#39;B: {}\u0026#39;.format(self.__class__.__name__) a = A() b = B() 此时执行super(B)将返回一个未绑定的类\n\u0026gt;\u0026gt;\u0026gt; super(B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, NULL\u0026gt; 而super(B,B)则会返回\n\u0026gt;\u0026gt;\u0026gt; super(B, B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, \u0026lt;B object\u0026gt;\u0026gt; 此时输出super(B).method在一些说明中会指出将返回一个未绑定的方法（像\u0026lt;unbound method A.method\u0026gt;）,但在当前的实现中，将是如下状况\n\u0026gt;\u0026gt;\u0026gt; super(B).method AttributeError(\u0026#34;\u0026#39;super\u0026#39; object has no attribute \u0026#39;method\u0026#39;\u0026#34;) 而同时并不像博客中所说，super(B,B)的行为现在也有所不同\n\u0026gt;\u0026gt;\u0026gt; super(B, B).method \u0026lt;function A.method at 0x059976A0\u0026gt; # 而在调用这个函数的时候，可以通过手动将一个对象为参数来使其正确执行 \u0026gt;\u0026gt;\u0026gt; super(B, B).method(b) B 未绑定的代理对象，必须要指定一个对象绑定，才可以继续正常使用，例如\n\u0026gt;\u0026gt;\u0026gt; super(B).__get__(b, B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, \u0026lt;B object\u0026gt;\u0026gt; # 这个对象与super(B, b)相同 \u0026gt;\u0026gt;\u0026gt; super(B).__get__(b, B).method() b Guido对这一个用处有一个回应：\nThanks for proposing this \u0026ndash; I\u0026rsquo;ve been scratching my head wondering what the use of unbound super() would be. :-) I\u0026rsquo;m fine with killing it \u0026ndash; perhaps someone can do a bit of research to try and find out if there are any real-life uses (apart from various auto-super clones)?* \u0026mdash; Guido van Rossum\n有点茴字的四种写法的味道了。\nsuper()在python3 # python3 中super()是最通常使用的一种方式， super()通常（只能被）使用在class定义中，用来返回一个父类的代理.\n这个用法起初在PEP3135提出，本是基于DRY原则为了避免在原本的用法中出现的两个问题：1.原本super(class_name,self)的用法会在类定义的多个地方重复类名，如果类名改变，则多处的class_name也需要改变，这样就容易遗漏。2.在使用类装饰器的class中类名指定的类并不是原本方法所在的类对象，这样造成的行为与期望产生差距\nGuido原本设想super作为一个keyword，然后使用cell来实现super可以指代当前的类，但之后他认为这个idea“too magic”，重新赞成使用super()来实现，并需要一个magic变量__class__来作为一个妥协方法\n这样当在类中使用super变量时，会寻找__class__来组合闭包，当你在全局范围类将super重命名为s，然后在类中使用s()，就会出现异常RuntimeError: super(): __class__ cell not found，但依然可以如同通常方式一样工作。另外一个有趣的地方在于，只要在s()之前引用__class__或super(仅仅只需要在s()之前出现)，s()就会如同super()一样正常工作。\nsuper()被广泛使用得以避免了一个问题：super在使用中会被误用为super(type(self), self)或super(self.__class__, self)，这时，在以下的情况会进入无限循环\nclass A: def method(self): print(\u0026#34;A\u0026#34;) class B(A): def method(self): super(type(self), self).method() print(\u0026#34;B\u0026#34;) class C(B): def method(self): super(C, self).method() print(\u0026#34;C\u0026#34;) C().method() 在这里C().method()，调用了super(C, self).method()，此时调用的是B的method()方法，但其中的 type(self)参数，所返回的类依然是C，而不是期望中的B，这样super(type(self), self) 依然是B类自身。\n__mro__的构造和C3线性化方法 # 在python2.3之前的版本中，__mro__基本遵循继承顺序自左向右深度优先的属性构造，而在python2.3中引入了新式类，所有的类继承链的根部均为object对象，这样就很容易构造一个钻石形的继承图，例如：\nclass A(object): def __getattribute__(self, name): pass class B(A): def __getattribute__(self, name): pass class C(A): def __getattribute__(self, name): pass class D(B, C): def __getattribute__(self, name): pass 构造的继承图如下 按python2.2中的线性化方法，类D的mro顺序为D-\u0026gt;B-\u0026gt;A-\u0026gt;C-\u0026gt;A。这样，当在D中使用__getattribute__()方法时，super().__getattribute__()调用B中的__getattribute__()方法，然后调用A.__getattribute__()，由于A的__getattribute__()直接继承自object，而object作为根类并不会调用super(),这样C的__getattribute__()方法就被忽略了。\n在出现这样钻石继承图的情况中，一个替代的解决方法是自己组织调用层次来避免如以上的情况（或者重复调用A中方法的情况）。\n# 一个替代方法 class A: def method(self): pass class B(A): def _method(self): # 这里写B独有的方法部分 pass def method(self): self._method() A.method(self) class C(A): def _method(self): # 这里写C独有的方法部分 pass def method(self): self._method() A.method(self) class D(B, C): def _method(self): # 这里写D独有的方法部分 pass def method(self): self._method() B._method(self) C._method(self) A.method(self) 这种办法一方面将一个完整的方法分割到了两个函数中，对于方法的理解存在负面影响。更加严重的是，这个方法导致在实现D的method()方法时，必须了解类B，C的实现，并协调A的method()方法，这样原本为封装信息的继承方法造成了信息泄露；同时将继承结构的细节与D类绑定了，这样若之后要对B或C类的继承方式做修改时，需要同时修改它们的子类。\n在python2.2及之前的版本中，钻石型继承并不常出现，而在2.3版本中引入了新式类\u0026ndash;一个关键点在于所有的类继承自object\u0026ndash;造成了钻石形的继承关系出现次数大大增加。这样，引入一个新的线性化算法就变得必要了。[1]\nC3线性化算法 # 前置的约定：\n我们用ABCD\u0026hellip;N来指代由A-\u0026gt;B-\u0026gt;C-\u0026gt;D\u0026hellip;-\u0026gt;N的mro，其中A为mro的头部，其余作为尾部\n设定A + B\u0026hellip;N = AB\u0026hellip;N\n用L(C)来表示C的线性化结果\n那么，C3算法可以被描述为以下几条原则：\n设一个类C，C线性化后的mro为C与对C的父类mro和C的继承顺序构造的一个mro做合并操作的结果之和， 用公式描述则是：L(C) = C + merge(L(A), L(B), ..., AB...)\n根类的mro为它自己, 也就是有L(O) = O\nmerge的算法是: 在merge的参数中，先选择一个mro的头部，如果这个头部不在之后所有的mro的尾部中，那么就将这个头加入merge结果的mro中，并在其他参数的mro中去除这个头部， 否则选择下一个mro。重复这个过程，直到merge中没有元素，或者无法找到头部（此时抛出一个异常）。\n算法本身描述比较抽象，只要用一个例子说明，就会很容易理解：\n先构造一系列类：\nO = object class F(O): pass class E(O): pass class D(O): pass class C(D,F): pass class B(E,D): pass class A(B,C): pass 这些类存在着如下图的继承关系：\n此时根据算法有：\n# O 的mro为O本身 L(O) = O L(F) = F + merge(L(O), O) = F + merge(O, O) = F + O = FO L(E) = EO L(D) = DO 继续：\nL(C) = C + merge(L(D), L(F), DF) = C + merge(DO, FO, DF) # 先选择DO的头部D，D不在FO的尾部中，D同时是DF的头部， # 所以将D作为merge结果的头部，并且在参数中去掉D = C + D + merge(O, FO, F) # 同理 = C + D + F + merge(O, O) = CDFO L(B) = BEDO L(A) = A + merge(L(B), L(C), BC) = A + merge(BEDO, CDFO, BC) = A + B + merge(EDO, CDFO, C) = A + B + E + merge(DO, CDFO, C) = A + B + E + C + merge(DO, DFO) = A + B + E + C + D + merge(O, FO) = A + B + E + C + D + F + merge(O, O) = ABECDFO 可以看到C3线性化方法中，E类相比类C在继承顺序上更接近与根O，但是mro中位置却在C之前。C3线性化的一个优点在于整个继承结构中的所有的类的mro均是单调的，也就是说C3线性化方法具有单调性。\nsuper()实现 # 使用者通过super()返回的代理对象来获取对应对象的属性，可以通过将super()实现为一个描述器来做到这一点。\nclass new_super: def __init__(self, type=None, object=None): if type is None: # super利用__class__组成闭包，这时__class__指向定义时所在的类，而不是运行时 # 在具体的实现中，__class__在编译时被写入闭包 if __class__ is None: raise RuntimeError(\u0026#34;super(): no arguments\u0026#34;) self.__type__ = __class__ else: self.__type__ = type self.__object__ = object def __get__(self, obj, type=None): # 如果没有指定第二个参数，可以用__get__方法来与obj绑定 if type is not None and self.__object__ is None: return new_super(self.__type__, obj) else: return self def __getattr__(self, attr): if isinstance(self.__object__, self.__type__): starttype = self.__object__.__class__ else: starttype = self.__object__ mro = iter(starttype.__mro__) for cls in mro: if cls is self.__type__: break for cls in mro: if attr in cls.__dict__: x = cls.__dict__[attr] if hasattr(x, \u0026#39;__get__\u0026#39;): x = x.__get__(self.__object__) return x raise AttributeError "},{"id":3,"href":"/posts/q_magic/","title":"Q's magic","section":"Posts","content":" 前言 # Q 是一个开源库，正如它介绍里所写的那样，它是用来“Quick and dirty debugging output for tired programmers.”，Q的用法主要有两种：\nimport q之后， 使用q(value)来 print value 的值，或是使用q/value， 或者q|value，只要在想 print 的值前加“q/”或“q|”的前缀，即可以print值\n在函数定义前加@q的修饰器,可以print 函数参数，返回值，运行时间等信息 本文用来展示q这个库是如何在300+行代码的篇幅下，完成这样的功能的。\nimport q之后为什么可以直接使用q()和@q # 想做到这件事的办法可以想到，如同其他语言一样q()需要被实现成一个全局的静态函数，在python中，则是在import时完成class q的实例化，那么另一个问题是，q 中 class 名是 Q ，那么调用应该是Q.q()，而不是q()，这部分的实现关键在于它将自己装载在了sys.module中,通过这条语句sys.modules['q'] = Q()并在class中实现__call__()函数，使得可以直接使用q()\nq/value如何实现 # q/value 修改一下格式就变为 q / value， 同时源码里也可以看到其中有__truediv__()函数，于是发现这里的实现在于 q 重载了/和|运算，使得这个运算符在执行了q print的操作之后返回__truediv__()的第二个参数。\nobject.truediv(self, other) 调用这些方法来实现二进制算术运算 (+, -, *, @, /, //, %, divmod(), pow(), **, \u0026laquo;, \u0026raquo;, \u0026amp;, ^, |)。例如，求表达式 x + y 的值，其中 x 是具有 add() 方法的类的一个实例，则会调用 x.add(y)。 python数据模型\n这里可以看到 q/value 时会调用 q 的__truediv__()函数，这样在 q 重载了这个函数的时候，达到了重载操作符的效果。\n@q如何实现 # q被调用时调用了__call__()函数，这个函数主要做了有关的几件事：self.inspect.getframeinfo(self.sys._getframe(1), context=9)通过getframeinfo()来获取调用附近的代码文本块，打印被修饰函数的基本信息，然后扫描文本块返回self.trace(), python 定义修饰器需要返回一个以修饰函数 func 为参数的 wapper 函数，那么可以想到 trace 里会返回 wapper，那么在这里，则是返回了self.functools.update_wrapper(wrapper, func)。\nfunctools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) 更新一个 wrapper 函数以使其类似于 wrapped 函数。 可选参数为指明原函数的哪些属性要直接被赋值给 wrapper 函数的匹配属性的元组，并且这些 wrapper 函数的属性将使用原函数的对应属性来更新。 此函数的主要目的是在 decorator 函数中用来包装被装饰的函数并返回包装器。 如果包装器函数未被更新，则被返回函数的元数据将反映包装器定义而不是原始函数定义，这通常没有什么用处。 module-functools\ntrace 里仅仅是定义了wapper(),而在wapper()中执行了 func，然后返回了 func 的返回值，在这里修饰器得到了 func 的参数，(q.__call__(self, *args),这里被作为修饰器调用时，args[0] 是被修饰的函数，这个参数被传到了 trace 里)因此可以遍历参数并 print 它们的值，func 在wapper 中执行，这样也可以 print 返回值\n在处理error时会有些麻烦，因为 func 是在 q 的wapper()中运行的，异常抛出时会抛到 wapper 的 栈帧，这里需要在 wapper 中获取 error 信息，这是通过 self.sys.exc_info()来做到的，通过 print error_trace_back.tb_next 可以正确显示异常。\nreference # https://github.com/zestyping/q http://pyvideo.org/video/1858/sunday-evening-lightning-talks#t=25m15s "},{"id":4,"href":"/posts/read_flask_source_code_1/","title":"Flask 源码阅读（1） : request的处理流程","section":"Posts","content":" 前言 # 本系列试图从flask 1.0版开始阅读一个完整的项目，不同于常见的追踪启动后行为来阅读源码的方式，这一个系列的文章打算从写一个符合wsgi方式的web框架开始，然后逐步完善添加功能的方式来写阅读笔记。\nwsgi规范 # def app(environ, start_response): start_response(\u0026#39;200 OK\u0026#39;, [(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/plain\u0026#39;)]) yield \u0026#34;Hello world!\\n\u0026#34; 一个简单的 wsgi 规范的 app 会被构建为以上的形式。其中app作为即将扩展的部分，需要被实现为一个 Callable 对象，它接受 environ 和 start_response 两个参数，并返回一个字节序列。\nflask 的app实现 # 以上提到 app 需要被实现为一个 callable 对象，那么，作为主体的 Flask 类则要定义 __call__() 函数。\ndef __call__(self, environ, start_response): return self.wsgi_app(environ, start_response) 可以看到__call__ 函数其实只是返回了wsgi_app(environ, start_response)， 真正的app主体在 wsgi_app上，__call__() 只是它的一个包装。通过这种方式可以分离 app 方法，便于对 app 进行修改。\n观察wsgi_app() 方法\ndef wsgi_app(self, environ, start_response): ctx = self.request_context(environ) error = None try: try: ctx.push() response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) 方法主体十分简单，首先根据 environ 构造 context ， 然后通过 full_dispatch_request() 解析请求返回函数 response ，response(environ, start_response) 函数返回真正需要获得的字节序列。\nrequest_context() 函数 # def request_context(self, environ): return RequestContext(self, environ) 返回了 RequestContext 类， 暂且跳过。\nfull_dispatch_request() 函数 # def full_dispatch_request(self): self.try_trigger_before_first_request_functions() try: request_started.send(self) rv = self.preprocess_request() if rv is None: rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) 如上所说，full_dispatch_request() 函数作为主体主要执行了以下几件事\ntry_trigger_before_first_request_functions() : 这个函数并不复杂，简单来说是在第一个 request 之前初始化并依次执行self.before_first_request_funcs中的函数。\nrequest_started.send(self) : 这一部分request_started作为_FakeSingnal对象用来发送 request start的信号\npreprocess_request() : 预处理请求，先由上下文栈弹出蓝图，调用url_value_preprocessors.get(none， ())来获取针对所有 url 值需要的函数，如果有针对所有 url 都起作用的视图函数，则在此调用。接下来调用每一个使用before_request装饰的可作用于所有 request 的函数。如果其中某一个函数返回一个值，这个值将会作为视图返回值 处理并停止进一步的请求处理。\ndispatch_request() ：本函数进行url匹配，返回视图函数返回值。由栈顶弹出 request，然后rule = req.url_rul，如果 rule 含有 provide_automatic_options，自动调用self.make_default_options_response()函数并返回。否则返回self.view_functions[rule.endpoint] (**req.view_args)，可以看出这里仅通过endpoint来匹配 view function 字典。\nfinalize_request() : 这个函数将先调用make_response(rv)视图返回值转变为真正的 response (这一部分之后再谈)。接下来是函数主要部分，process_response(response)函数获取上下文，获得蓝图和上下文中 request 之后需要调用的函数，接下来构造执行链 ctx.after_request_functions-\u0026gt;（逆置）bp.after_request_functions-\u0026gt;适用于所有的 request 的 （逆置） after_request_functions。按照执行链依次执行，最终储存session，结束request。\n小结 # 本文作为 flask 源码阅读的第一篇，简略的浏览了一遍 app 中关于 request 的处理流程，设计方式基本十分直观，主体分为三部分，在 request 之前，request 处理， request 之后构建了相关的执行链，并进行调用。 接下来一篇将试图观察视图函数的注册以及 route 部分的实现。\n"},{"id":5,"href":"/posts/from_zero_to_a_python_interpreter_1/","title":"从零开始的python解释器（1）","section":"Posts","content":" 单条字节码的解释运行 # 反编译字节码 # python 字节码形式可以用dis.dis()来反编译code object来获得，先考虑一段简单的python代码:\na = 1 b = a + 1 反编译之后是： 可见字节码拥有2Byte长度，前半部分用来标识字节码，后半是参数。其中字节码的参数仅用来标识字节码参数的位置，而不是参数本身。\n字节码来源 # code object是由compile()函数编译代码字符串生成的。在当前要进行的部分暂时关注它的一部分内容：\ncode.co_code = b\u0026#39;d\\x00Z\\x00e\\x00d\\x00\\x17\\x00Z\\x01d\\x01S\\x00\u0026#39; code.co_consts = (1, None) code.co_names = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) 以上则是解释运行暂时需要的全部材料，其中co_code则是python字节码，co_consts用来存储需要的常数，co_names存储需要的变量。\n举例：LOAD_CONST的解释 print(co_code[0])则会返回100，即是字节码， co_code[1]= 0则是字节码参数 通过dis.opname[100]则可知道字节码opname = LOAD_CONST,参数则是co_consts[0] = 1。这样第一条字节码就可以翻译为LOAD_CONST(1)\n字节码执行 # 由上知道了字节码本身被翻译为LOAD_CONST(1)，接下来就需要执行该函数 python vm与JVM相同，都是基于操作数栈的解释器，函数在执行后将返回值压入操作数栈 因此，LOAD_CONST()函数可以被写成以下形式\ndef LOAD_CONST(num): stack.push(num) 这样，第一条字节码便执行完成\n多条字节码顺序执行 # 这样可以写出字节码解释器主体的循环：\npc = 0 stack = [] def run(): while True: byteName, arguments = prase_byte_code_and_argument() dispatch(byteName, arguments) if byteName = \u0026#34;RETURE_VALUE\u0026#34;: return 此处，鉴于将来要对于循环和分支结构的支持，考虑通过判断RETURE_VALUE来返回退出循环。\nprase_byte_code_and_argument()函数 # 本函数用来解析code.co_code的字节码，转换为字节码函数名和参数。\ndef prase_byte_code_and_argument():\rbyteCode = code.co_code[pc]\rbyteName = dis.opname[byteCode]\rarguments = []\rpc += 2\rif byteCode \u0026gt;= dis.HAVE_ARGUMENT:\rarg = code.co_code[pc-1]\rif byteCode in dis.hasconst: # Look up a constant\rarg = code.co_consts[arg]\relif byteCode in dis.hasname: # Look up a name\rarg = code.co_names[arg]\relif byteCode in dis.haslocal: # Look up a local name\rarg = code.co_varnames[arg]\relif byteCode in dis.hasjrel: # Calculate a relative jump\rarg = pc + arg\relse:\rarg = arg\rarguments = [arg]\relse:\rarguments = []\rreturn byteName, arguments dispatch(byteName, arguments)函数 # 获取到byteName之后要得到对应的函数对象，此时使用getattr(byteName)来获取对应的函数对象 然后调用byteName(*arguments)完成执行\ndef dispatch(byteName, arguments): func = getattr(vm, byteName) func(*arguments) RETURE_VALUE # return value暂时仅作为字节码的终止，因此判断运行到此处时退出主循环。\n总结 # 最简单的字节码求值器的主题就这样写成了，剩余的其他工作即是填充上未写过的字节码函数定义，这样字节码的解释求值即可以完成了。\n"},{"id":6,"href":"/posts/juc_aqs/","title":"JUC包AQS设计","section":"Posts","content":" 为什么需要AQS JUC包中提供了一系列的同步器，这些同步器都有以下基本功能 内部同步状态的管理 内部同步状态的设置 使一个线程被阻塞 使线程被其他线程唤醒 几乎任何一个同步器都可以用来设计其他的同步器，因此将共有部分抽象并设计框架成为一个符合直觉的需求 AQS设计需求 功能目标 基本方法，Acquire和Release 阻塞和非阻塞操作 可选的超时设置 通过中断实现的任务取消，通常是分为两个版本，一个 acquire 可取消，而另一个不可以 独占与非独占模式 监控形式的await/signal 操作 性能目标 AQS结构 acquire和release while (synchronization state does not allow acquire) {\renqueue current thread if not already queued;\rpossibly block current thread;\r}\rdequeue current thread if it was queued; update synchronization state;\rif (state may permit a blocked thread to acquire)\runblock one or more queued threads; 同步状态的原子性管理 AQS使用了一个32位int保存state，并提供getState, setState, 和compareAndSet来读取和操作 在CyclingBarrier中使用了64位state， 因此利用了锁来完成原子性操作 线程的阻塞与解除阻塞 通过JUCLockSupport park和unpark来控制阻塞和feizuse park是基于线程设置的，而不是基于同步器 unpark是没有计数的，因此可能有多余的unpark附在线程上 队列的管理 阻塞队列采用严格的FIFO链表队列，使用了变体的CLH锁。 为解决取消和超时功能，待选MCS锁变体 节点通过自旋和CAS操作插入，每个节点状态被保存在它的前驱，因此自旋阻塞类似while(node.pred.state != release); CLH锁的优点在于节点的入队与出队总是快速， 无障碍且无锁的，而且由于每个节点的状态保持在前驱，使得修改节点可以分散进行； 一个节点的前驱修改其状态，他的后继在下一次自旋时即会发现状态的改变，在阻塞队列中，则需要前驱节点去显式的唤醒（即unpark。 其中节点的next的仅为一种优化，这个队列是由prev所链接的，由于缺少应用于双向列表的CAS操作，next仅仅是直接赋值的。因此在唤醒时使用next来找到需要唤醒的节点，next不存在也并不能证明后继不存在，需要由tail前溯来确认。 节点在前驱中的状态是用于控制阻塞而不是自旋，在同步器中，线程仅在tryAcquire返回true时才在acquire返回。 活动线程在队首时，仅允许tryAcquire来获取锁，也可能Acquire失败而重新堵塞，此时是通过检查前驱是否为head来确认解除许可。取消状态也必须在状态位实现，因此单bit的release位并不够。 设置状态同时可以避免多余的park和unpark，在线程park前，设置signal位并检查同步状态和节点状态。线程release时重置状态，这样显性的标识状态可以避免多次阻塞及引入多次冲突的开销。 Acquire操作 if (!tryAcquire(arg)) {\rnode = create and enqueue new node;\rpred = node\u0026#39;s effective predecessor;\rwhile (pred is not head node || !tryAcquire(arg)) {\rif (pred\u0026#39;s signal bit is set)\rpark();\relse\rcompareAndSet pred\u0026#39;s signal bit to true;\rpred = node\u0026#39;s effective predecessor;\r}\rhead = node;\r} release if (tryRelease(arg) \u0026amp;\u0026amp; head node\u0026#39;s signal bit is set) {\rcompareAndSet head\u0026#39;s signal bit to false;\runpark head\u0026#39;s successor, if one exists\r} 条件队列 #TODO AQS使用 AQS作为模板提供给子类，子类仅需要设置更新状态。在JUC包中的同步器使用了一个内部类来包装AQS，重写了tryAquire和tryRelease来控制同步。 AQS提供了多个版本的Aquire和Release，包括超时和中断版本。并提供了tryAcquireShared来控制可重入的资源，方法通过返回值通知框架所剩资源状况，在release时框架通过级联来唤醒多个节点。 公平与非公平功能： 在一些条件下，非公平的获取锁可以有效提高同步器吞吐量，而如果外来线程可以持续抢占锁则会造成队列中线程饥饿。 FIFO队列在进入之前线程会调用tryAcquire方法，因此获得了一个与队头线程竞争的机会，从而可以实现公平与非公平的竞争，此时可以修改tryAcquire中对资源的请求次数来使其偏向外来线程；如果要实现严格的公平竞争，则可以通过添加约束，使线程只有入队才能调用tryAcquire。 一个比完全公平竞争优化的方法：在lock队列为空时，线程可以使用tryAcquire来获取锁，这样有一个线程可以不必入队获取到锁，得到性能的一点优化。 Reference http://gee.cs.oswego.edu/dl/papers/aqs.pdf https://www.inoreader.com/article/3a9c6e78f01cc939-juc-aqs "},{"id":7,"href":"/posts/effecient_method_of_scotty/","title":"斯科特杨的高效率方法","section":"Posts","content":"在阅读了Scoltt Yang的几本关于高效率的书之后，总结并试着运用了一些关于高效率的方法，在这里做一些总结。\n日/周目标清单 # 建立一个周目标清单，并在每天开始的时候将清单中的一些任务添加到日目标清单中。\n每天日目标清单中的主要工作应该不超过3个，可以让你分配主要的精力在这些任务上面。（这条原则来自于《精力管理》）\n在做完清单中的所有项之后立刻开始休息，即使你仅使用了3个小时就完成了今天的任务，也要避免继续添加今天的任务，正如我们在小时候会有即使做完作业也会被父母继续添加任务这样的经历，我们应当避免把日目标清单变成普通的todo-list，从而减少每天完成任务的动力。\n每周工作六天，在每周的最后一天不要设置任何需要大量精力的任务，为自己思考休息提供充足的空闲，给自己干涸的电池充满电。\n精力管理 # 我们在工作时应当管理的是我们的精力和任务，而非时间。\n安排你的食物，少食多餐，每天吃4-6餐。\n工作90-120分钟休息一次，注意力是消耗品，同时也需要锻炼。\n将每天固定要做的事建立为习惯，让这些事自动完成。\n做自己想要去做的事，而不是应该去做的事。\n建立习惯 # 30天建立一个习惯，并将它写在纸上或者以文档记录下来，在最初的30天之内，一旦在某一天停止就重新开始计数，重新坚持30天。 之后便可以不必坚持的如此严格，身体会自动将它完成。\n选择要建立的习惯时推荐阅读《Zen to do》\n批处理 # 生活中有大量的事情可以使用批处理来解决，把大量原本填充到其他空余时间的事情集中解决，从而可以节省出大量额外的时间。\n以下几类事情可以使用批处理的办法来解决：\n阅读 集中阅读订阅的博客或者文章，每日学习工作中的阅读任务也可以批处理来解决。 邮件处理/拨打电话/社会联系 作业/写博客/电脑工作 一次性做这些工作可能会花费大量的时间，但是可以避免每天进入专注时花费的时间，也不必使自己承受拖延的痛苦。 清扫/购物 将家务之类的事务在每周的某一天集中完成，可以避免陷入无尽的家务漩涡。 思考/设置目标 在周日把自己的项目或者一些任务放入自己的周清单，使用完整的一块时间来进行计划，远比使用小段时间计划要好。 "},{"id":8,"href":"/about/","title":"About","section":"","content":"我是b1indsight， 这是我的twitter。\nabout还没写，我好懒\n"}]