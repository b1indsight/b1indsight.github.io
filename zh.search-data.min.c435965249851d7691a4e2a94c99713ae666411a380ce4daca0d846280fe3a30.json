[{"id":0,"href":"/posts/","title":"Posts","section":"","content":" 正常事故 在查尔斯·佩罗的《高风险系统与正常事故》（后面简称《正常事故》）这本书中，作者认为一些高风险技术的特征表明，不管常规安全措施如何，一种事故的发生是不可避免甚至是正常的。本期的主要内容便是自三里岛事故的部分介绍开始，对正常事故的一些讨论。 Super函数和mro算法 super()作为在python中常被使用到的一个方法而言，具有一些有趣的特性，本文可以看作super()的一个考古，主要包括以下几个部分： 2020 年终总结 2020 年度总结 Infinity stream 无穷流的实现 Q\u0026#39;s magic 前言 # Q 是一个开源库，正如它介绍里所写的那样，它是用来“Quick and dirty debugging output for tired programmers.”，Q的用法主要有两种： import q之后， 使用 2020.09.07-2020.09.13 2020.08.31 - 2020.09.06 # 上周总结 # 重写虚拟机，开始做了一部分，试图要做的部分比想象的要多很多，基本上所有的类都要重新设计，看起来不是一周可以完成的工作量 A Philosophy 2020.08.31-2020.09.06 2020.08.31 - 2020.09.06 # 上周总结 # 上周计划的三件事： Ts ts入门写了hello，world，依然没有找到什么项目可以做，考虑写一下vscode的扩展，或者在g 2020.08.24-2020.08.30 新的系列：周总结和月总结 Flask 源码阅读（1） : request的处理流程 前言 # 本系列试图从flask 1.0版开始阅读一个完整的项目，不同于常见的追踪启动后行为来阅读源码的方式，这一个系列的文章打算从写一个符合ws 从零开始的python解释器（1） 最基础的字节码序列求值器的实现 JUC包AQS设计 基本是JUC论文读书笔记，没什么独创性，#TODO具体实现及补充 进程与线程 本文主要介绍进程与线程的概念，主要问题，进程间的调度与同步。 斯科特杨的高效率方法 简单构建的可行提高效率体系 "},{"id":1,"href":"/posts/normal_accident/","title":"正常事故","section":"Posts","content":"在查尔斯·佩罗的《高风险系统与正常事故》（后面简称《正常事故》）这本书中，作者认为一些高风险技术的特征表明，不管常规安全措施如何，一种事故的发生是不可避免甚至是正常的。本期的主要内容便是自三里岛事故的部分介绍开始，对正常事故的一些讨论。\n三里岛事故 # 让我们首先从1979年的三里岛核电厂事故看起，这指的是1979年3月28日三里岛核电站发生的一次部分堆芯熔毁事故，场内污染清理从1979年8月开始，直到1993年12月结束。在查尔斯·佩罗写作《正常事故》这本书的时间点看起，三里岛事故是迄今为止最严重的核电厂事故，而相对于现在来说，依然是美国商用核电历史上最严重的事故。首先介绍一些相关系统的信息。\n机组的结构简图如下：\n可以转化为下图的示意图：\n系统简述 # 反应堆正常工作时，初级冷却系统的水始终保持高温高压流经堆芯，经过蒸汽发生器淋到次级冷却系统的水管上，次级系统的水转化为蒸汽驱动涡轮发电机。\n初级冷却系统涉及以下一些自动安全装置：\n自控减压阀在堆芯压力过高时放出堆芯的水来减少压力，但是自控减压阀开启时间不宜过长，因为当排出的水过多压力太低，高温的水将变成蒸汽泡阻塞初级冷却系统，会阻碍冷却水流动，造成部分位置过热并再次启动裂变反应。 为了防止压力降低之后高温水变为蒸汽，两个反应水冷却泵会自动启动向初级冷却系统注水降温。 高压注入泵向堆芯注入高压冷却水降低温度。但是高压注入泵注入的高压冷水可能使堆芯产生裂痕，为防止高压注入泵的副作用，高压注入泵和堆芯之间通过缓压器来减少压力。缓压器是一个下半部为水上半部为蒸汽的罐子，当注入的水过多，缓压器会被注满，可能导致冷却水管破裂，造成失水事故，严重的情况会导致堆芯熔融。 次级冷却系统保持高压，次级冷却系统的水与初级冷却系统保持隔离，而且鉴于涡轮机叶片十分精细，所以必须保持纯净，因此有一个冷凝水净化系统来清除微粒。紧急给水泵在主供水泵停机时将紧急储水箱的水抽出来，维持次级冷却系统工作，两个管道阀门均含有指示灯。 事故发生 # 冷凝水净化器在二号堆启用几个月后坏过3次，而3月28日凌晨4点汽轮机不转了，事后分析是由于净化器封焊口漏出大约一杯水量的水。水的湿气进入了仪器控制系统，结果导致水泵停止工作，冷水不再流动，于是汽轮机随后停止。\n紧急给水泵随后试图供水，用来补充次级供水系统的水，但是两天前检修后，管道阀门全是关闭位置，操作者知道紧急给水泵在运行，但是并不知道管道不通。这两个供水指示灯虽然指示阀门关闭，但是其中一个灯被挂在开关上的修理标签遮住了，鉴于操作者没有想到阀门是关的，所以并没有立刻去看阀门指示灯，而在八分钟之后才发现阀门没打开，但此时已经造成一部分危害。\n进入事故状态13秒，次级冷却系统缺水之后，蒸汽发生器很快烧干，初级冷却系统温度居高不下，堆芯无法冷却，因此反应堆急停，但是衰减的放射性物资仍然还在产生热量。高压触发自控减压阀，放出堆芯的水到缓压器，因为自控减压阀不能开启过长，并且堆芯压力迅速下降，于是操作者决定关闭自控减压阀，但是由于出现一些故障，导致自控减压阀没有完全关闭，冷却水仍然在漏出。鉴于减压阀在之前出现过故障，前不久为此加了一个指示灯，以便操作者观察是否复位，但是指示灯在阀门收到关闭脉冲时标志阀门关闭，而不是阀门事实上关闭，于是操作者认为自控减压阀一切正常。\n在进入事故状态后的两三分钟内，水不断通过自控减压阀漏出，但是堆芯温度并没有下降，这样过热的水即将变为蒸汽，于是反应水冷却泵向堆芯注水，此时由于未知的原因造成了冷却水稳定的假象，一切似乎有所控制。\n进入事故状态的两分钟后，冷却水并未稳定，此时堆芯仍然在失水，初级冷却系统中压力剧降，高压注入泵自动启动，因为之上提过的高压注入泵的原因，高压注入泵在注入2分钟之后就被操作员手动降低了注入速度。高压注入泵启动之后，一个表指出堆芯压力正在减少，而另一个指示表显示缓压器压力正在升高。此时的状况使操作者迷惑不解，一般情况下缓压器和堆芯压力升降趋势应该一致，此时选择相信哪一个指示表造成了一个两难问题，而反应堆的生产厂家和用户都很注意在培训时让操作者树立缓压器不能注满的观念，此时操作者选择更加熟悉的高压注入和缓压器的相互关系，急剧降低了高压注入速度。\n二号堆的设计造成无法直接测量堆芯水面高度，但是此时还有三个读数可能了解到发生失水事故，一个是污水池压力，水经由自控减压阀-\u0026gt;缓压器被排放到污水池，污水池压力增加。但是设计者不认为这是一个重要指标，指示灯布置在七英尺高控制板背面靠近底部的位置，在没有人意识到发生失水事故的情况下，查看度数是个费力不讨好的动作，所以谁也不乐意去看。另一是污水池温度，污水池接受堆芯内的高温水，导致温度升高。但是有一个自控减压阀已经漏水好几个星期，冷却水总是漏出，导致污水池温度总是偏高。剩余一个读数是堆芯压力，但是正如之前所说，操作员相信堆芯压力指示表有问题，因为它与缓压器压力读数相矛盾。\n在进入事故状态四五分钟后，由于初级冷却系统失水，反应水冷却泵没有足够水流过，开始剧烈颤动，声音大到控制室都可以听到。操作者们紧急开会之后，鉴于水泵可能顶不住如此剧烈的颤动，于是决定紧急关泵。\n在进入事故状态2小时20分钟之后，终于有人意识到自控减压阀出了问题，发现阀门并没有复位，于是紧急关闭了一个截止阀。在事后听证会上，一位操作者作证这这个措施是忙乱中瞎碰运气，幸好这个措施及时阻止了堆芯完全熔融。\n进入事故状态33小时，控制室的人听到了轻微爆炸声，安全壳压力计度数突然跳到了安全壳设计极限的一半。这是由于堆芯燃料棒的锆合金外壳与水蒸气发生反应放出氢气，形成氢气泡，氢气可能从堆罩中经自控减压阀进入安全壳，造成氢气爆炸。在场的某人知道发生了氢气爆炸，于是让另一名操作者不要再启动一台出故障的水泵（水泵马达启动时会产生火花）。\n正常事故 # 在大多数高风险系统中，由于系统的一些特性导致事故是不可避免的，以至于产生事故被看作是自然发生的，我们把这些事故叫做正常事故。三里岛事故就是一个典型的正常事故。\n正常事故有几个典型的特征：系统中的各组件作用是预料外的，而且在紧要关头是不可理解的；由于系统特征，事故的破坏速度显著超过维护者抢救的速度，破坏范围不断扩大，而事故层出不穷。\n考虑第一个特征，三里岛事故可以看作是由一些故障复合而成的，分别是1.净化器漏水，2.紧急给水泵阀门被误关闭，3.自控减压阀无法复位，4.自控减压阀的指示灯失灵。这四个故障如果单独发生，仅仅是连事件都算不上的小问题，如果提前得知这些故障，也无从想出会产生这样的事故，因此可以把这个事故划为系统事故，即多重故障以不可预期的方式相互作用。在操作者的视角观察，净化器漏水导致汽轮机停机几乎预想不到；次级冷却系统故障导致初级冷却系统烧干也很难立刻联想到，或者说等到联想到这个问题，已经太迟了；缓压器与堆芯由管道连接，但是缓压器压力上升而堆芯压力迅速下降，此时也造成了疑惑，鉴于之前从未发生失水事故，因此操作者能全面接受堆芯压力指示而无视手册上防止缓压器注满的警告，这一要求也显得强人所难；堆芯发生锆-水反应导致氢气爆炸同样是不可理解的。这些系统的运行路径均是超过设计的生产路径的，而产生的警告信号必须要能与思维模式吻合才能使操作者理解并产生警告效果。更不必说警告信号也同样是故障的。\n部分原因在于，这种人机系统中的相互作用确实 是看不见的(这里，“看不见的”取其本义) , 另一部分原因在于，即使能看见这种相互作用，人们也不相信。\n第二个特征就很好理解，事故破坏范围迅速扩大，在13秒的时间内蒸汽发生器便烧干了，堆芯自控减压阀启动，如果想对它做出什么处理的话，必须要求操作者理解次级冷却系统的故障造成了初级冷却系统的事故，这一切都要在13秒内进行。随后2，3分钟后两难问题出现，缓压器压力到达高点且在继续上升，堆芯压力却在下降，操作者需要在缓压器注满前紧急减少高压注水的速度（操作手册中如此写着），或是相信堆芯压力下降，冒着可能的（他们考虑中的）失水风险继续注水。事故状态四五分钟后，操作室又听到输运泵的震动，事故层出不穷。可以看到事故恶化的速度远超操作员理解的速度，操作员不得不在两到三分钟之内理解新的险情的运作方式才有可能做出正确决定，而这是显然不可能的。\n而产生正常事故这些特征的原因，主要在于系统组成的特征，查尔斯·佩罗在《正常事故》中提出了两个衡量标准，其一可以被称为复杂度，坐标轴的两端是线性系统-复杂系统。线性系统划分各个生产阶段，每个生产阶段在空间上分离,生产阶段内及生产阶段间主要保持序贯式的联系，系统中的反馈极少，而且反馈信息更多是直接的。复杂系统中每个生产阶段的组件相互接近，产生许多共模联系，具有不熟悉或预想不到的反馈回路，指标和控制参数之间相互作用，系统的状况需要从反馈信息中推断而不是直接获得，另外有一些完全没搞清的工艺过程。\n另一系统衡量标准是系统的配合特性，坐标轴的两端是紧配合-松配合，在紧配合的系统中工序的工艺流程相关性很高且难以拖延，同时工序恒定而通常环节设计为只有一种方式到达目标，另外紧配合系统具有很少的松弛环节，某一环节出错难以使用其它资源临时替代。而松配合系统则与之相反。在紧配合系统这些特征之外，我认为可以另一导致紧配合系统的特点在于系统中上一环节组件异常之后影响到下一环节所需的时间很短（特别是相对于操作者或决策者理解现状的时间），这可能会导致操作者无法做出正确应对，更糟糕的情况下会扩大事故影响范围。\n系统的复杂度和配合特性可以看作是两个相互独立的特征范围，在这两个坐标轴构成的坐标系中，具有紧配合的复杂系统这样的结构导致出现事故是不可避免的，甚至是正常的。\n一些附属的风险系统 # 错误引致系统 # 错误引致系统的特殊之处在于错误是由系统各组元的组合方式造成的，对组元的改进或变化，不是由其他部分不予合作而不行，或是其他部分将得到强烈表现而使变化毫无意义。《正常事故》中认为水上运输是一个错误引致系统，技术手段的进步促进了生产，但也促进了事故的发生。另外同样有利于巩固这个结构。\n自激系统 # 核武的侦测系统似乎是这一种系统，侦测方需要从环境噪音中正确判断信号，而鉴于后果严重，系统不仅需要防止故障，而且要杜绝故障被掩盖的可能性。攻击方则要使信号更加贴近环境噪音，缩短侦测者的反应时间，对侦测者施加破坏以造成故障。这样侦测系统的复杂度和配合特性的提升是有意造成且自我激发形成正反馈回路的。\n最后谈一些错误认知。在几乎所有的事故回顾中，严重疏忽和无能都是存在的，不安全的操作，偷工减料的设备，无视安全规范的设计层出不穷，一旦发生事故，人们总会找到容易发生重大事故的主要原因。在这里必须说明的地方在于，可以说组织无能是组织的正常状态，在生产压力下疏忽和错误也是不可避免的，即使出现一些错误征兆，人们也倾向于忽略它或是将它解释为熟悉的状态，几乎不可能为了事故隐患而每次停机，然而回顾往事时总能找到这些警告信号。\n"},{"id":2,"href":"/posts/super_and_mro_algorithm/","title":"Super函数和mro算法","section":"Posts","content":"super()作为在python中常被使用到的一个方法而言，具有一些有趣的特性，本文可以看作super()的一个考古，主要包括以下几个部分：\nsuper()的定义和用法 构造__mro__属性中类继承顺序线性化的算法 提供了一个super()的简单实现 super()的定义和用法 # 首先提供一个super(type, object-or-type)的定义：\n在object-or-type中__mro__指定的搜索路径中,返回type后的下一个类对象的代理。\n例如object-or-type的__mro__指定的查找路径为D-\u0026gt;B-\u0026gt;C-\u0026gt;A-\u0026gt;object, 并且type的值为B，则super(type, object-or-type)将返回路径中B的下一个类C的代理。\n关于未绑定的一个问题 # super()的两个参数都是可选参数，如果省略第二个参数，则返回一个未绑定的超类对象。在这个角度中，super()返回的代理对象与super()的第二个参数绑定。\n这一点可以用以下的代码测试：先构造两个类A，B，并初始化\nclass A(): def __init__(self): self.s = \u0026#39;a\u0026#39; def method(self): print(\u0026#39;obj A\u0026#39;) return self.s def __repr__(self): return \u0026#39;A: {}\u0026#39;.format(self.__class__.__name__) class B(A): s = \u0026#39;B\u0026#39; def __init__(self): super().__init__() self.s = \u0026#39;b\u0026#39; def method(self): print(\u0026#39;obj B\u0026#39;) super().method() return self.s def __repr__(self): return \u0026#39;B: {}\u0026#39;.format(self.__class__.__name__) a = A() b = B() 此时执行super(B)将返回一个未绑定的类\n\u0026gt;\u0026gt;\u0026gt; super(B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, NULL\u0026gt; 而super(B,B)则会返回\n\u0026gt;\u0026gt;\u0026gt; super(B, B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, \u0026lt;B object\u0026gt;\u0026gt; 此时输出super(B).method在一些说明中会指出将返回一个未绑定的方法（像\u0026lt;unbound method A.method\u0026gt;）,但在当前的实现中，将是如下状况\n\u0026gt;\u0026gt;\u0026gt; super(B).method AttributeError(\u0026#34;\u0026#39;super\u0026#39; object has no attribute \u0026#39;method\u0026#39;\u0026#34;) 而同时并不像博客中所说，super(B,B)的行为现在也有所不同\n\u0026gt;\u0026gt;\u0026gt; super(B, B).method \u0026lt;function A.method at 0x059976A0\u0026gt; # 而在调用这个函数的时候，可以通过手动将一个对象为参数来使其正确执行 \u0026gt;\u0026gt;\u0026gt; super(B, B).method(b) B 未绑定的代理对象，必须要指定一个对象绑定，才可以继续正常使用，例如\n\u0026gt;\u0026gt;\u0026gt; super(B).__get__(b, B) \u0026lt;super: \u0026lt;class \u0026#39;B\u0026#39;\u0026gt;, \u0026lt;B object\u0026gt;\u0026gt; # 这个对象与super(B, b)相同 \u0026gt;\u0026gt;\u0026gt; super(B).__get__(b, B).method() b Guido对这一个用处有一个回应：\nThanks for proposing this \u0026ndash; I\u0026rsquo;ve been scratching my head wondering what the use of unbound super() would be. :-) I\u0026rsquo;m fine with killing it \u0026ndash; perhaps someone can do a bit of research to try and find out if there are any real-life uses (apart from various auto-super clones)?* \u0026mdash; Guido van Rossum\n有点茴字的四种写法的味道了。\nsuper()在python3 # python3 中super()是最通常使用的一种方式， super()通常（只能被）使用在class定义中，用来返回一个父类的代理.\n这个用法起初在PEP3135提出，本是基于DRY原则为了避免在原本的用法中出现的两个问题：1.原本super(class_name,self)的用法会在类定义的多个地方重复类名，如果类名改变，则多处的class_name也需要改变，这样就容易遗漏。2.在使用类装饰器的class中类名指定的类并不是原本方法所在的类对象，这样造成的行为与期望产生差距\nGuido原本设想super作为一个keyword，然后使用cell来实现super可以指代当前的类，但之后他认为这个idea“too magic”，重新赞成使用super()来实现，并需要一个magic变量__class__来作为一个妥协方法\n这样当在类中使用super变量时，会寻找__class__来组合闭包，当你在全局范围类将super重命名为s，然后在类中使用s()，就会出现异常RuntimeError: super(): __class__ cell not found，但依然可以如同通常方式一样工作。另外一个有趣的地方在于，只要在s()之前引用__class__或super(仅仅只需要在s()之前出现)，s()就会如同super()一样正常工作。\nsuper()被广泛使用得以避免了一个问题：super在使用中会被误用为super(type(self), self)或super(self.__class__, self)，这时，在以下的情况会进入无限循环\nclass A: def method(self): print(\u0026#34;A\u0026#34;) class B(A): def method(self): super(type(self), self).method() print(\u0026#34;B\u0026#34;) class C(B): def method(self): super(C, self).method() print(\u0026#34;C\u0026#34;) C().method() 在这里C().method()，调用了super(C, self).method()，此时调用的是B的method()方法，但其中的 type(self)参数，所返回的类依然是C，而不是期望中的B，这样super(type(self), self) 依然是B类自身。\n__mro__的构造和C3线性化方法 # 在python2.3之前的版本中，__mro__基本遵循继承顺序自左向右深度优先的属性构造，而在python2.3中引入了新式类，所有的类继承链的根部均为object对象，这样就很容易构造一个钻石形的继承图，例如：\nclass A(object): def __getattribute__(self, name): pass class B(A): def __getattribute__(self, name): pass class C(A): def __getattribute__(self, name): pass class D(B, C): def __getattribute__(self, name): pass 构造的继承图如下 按python2.2中的线性化方法，类D的mro顺序为D-\u0026gt;B-\u0026gt;A-\u0026gt;C-\u0026gt;A。这样，当在D中使用__getattribute__()方法时，super().__getattribute__()调用B中的__getattribute__()方法，然后调用A.__getattribute__()，由于A的__getattribute__()直接继承自object，而object作为根类并不会调用super(),这样C的__getattribute__()方法就被忽略了。\n在出现这样钻石继承图的情况中，一个替代的解决方法是自己组织调用层次来避免如以上的情况（或者重复调用A中方法的情况）。\n# 一个替代方法 class A: def method(self): pass class B(A): def _method(self): # 这里写B独有的方法部分 pass def method(self): self._method() A.method(self) class C(A): def _method(self): # 这里写C独有的方法部分 pass def method(self): self._method() A.method(self) class D(B, C): def _method(self): # 这里写D独有的方法部分 pass def method(self): self._method() B._method(self) C._method(self) A.method(self) 这种办法一方面将一个完整的方法分割到了两个函数中，对于方法的理解存在负面影响。更加严重的是，这个方法导致在实现D的method()方法时，必须了解类B，C的实现，并协调A的method()方法，这样原本为封装信息的继承方法造成了信息泄露；同时将继承结构的细节与D类绑定了，这样若之后要对B或C类的继承方式做修改时，需要同时修改它们的子类。\n在python2.2及之前的版本中，钻石型继承并不常出现，而在2.3版本中引入了新式类\u0026ndash;一个关键点在于所有的类继承自object\u0026ndash;造成了钻石形的继承关系出现次数大大增加。这样，引入一个新的线性化算法就变得必要了。[1]\nC3线性化算法 # 前置的约定：\n我们用ABCD\u0026hellip;N来指代由A-\u0026gt;B-\u0026gt;C-\u0026gt;D\u0026hellip;-\u0026gt;N的mro，其中A为mro的头部，其余作为尾部\n设定A + B\u0026hellip;N = AB\u0026hellip;N\n用L(C)来表示C的线性化结果\n那么，C3算法可以被描述为以下几条原则：\n设一个类C，C线性化后的mro为C与对C的父类mro和C的继承顺序构造的一个mro做合并操作的结果之和， 用公式描述则是：L(C) = C + merge(L(A), L(B), ..., AB...)\n根类的mro为它自己, 也就是有L(O) = O\nmerge的算法是: 在merge的参数中，先选择一个mro的头部，如果这个头部不在之后所有的mro的尾部中，那么就将这个头加入merge结果的mro中，并在其他参数的mro中去除这个头部， 否则选择下一个mro。重复这个过程，直到merge中没有元素，或者无法找到头部（此时抛出一个异常）。\n算法本身描述比较抽象，只要用一个例子说明，就会很容易理解：\n先构造一系列类：\nO = object class F(O): pass class E(O): pass class D(O): pass class C(D,F): pass class B(E,D): pass class A(B,C): pass 这些类存在着如下图的继承关系：\n此时根据算法有：\n# O 的mro为O本身 L(O) = O L(F) = F + merge(L(O), O) = F + merge(O, O) = F + O = FO L(E) = EO L(D) = DO 继续：\nL(C) = C + merge(L(D), L(F), DF) = C + merge(DO, FO, DF) # 先选择DO的头部D，D不在FO的尾部中，D同时是DF的头部， # 所以将D作为merge结果的头部，并且在参数中去掉D = C + D + merge(O, FO, F) # 同理 = C + D + F + merge(O, O) = CDFO L(B) = BEDO L(A) = A + merge(L(B), L(C), BC) = A + merge(BEDO, CDFO, BC) = A + B + merge(EDO, CDFO, C) = A + B + E + merge(DO, CDFO, C) = A + B + E + C + merge(DO, DFO) = A + B + E + C + D + merge(O, FO) = A + B + E + C + D + F + merge(O, O) = ABECDFO 可以看到C3线性化方法中，E类相比类C在继承顺序上更接近与根O，但是mro中位置却在C之前。C3线性化的一个优点在于整个继承结构中的所有的类的mro均是单调的，也就是说C3线性化方法具有单调性。\nsuper()实现 # 使用者通过super()返回的代理对象来获取对应对象的属性，可以通过将super()实现为一个描述器来做到这一点。\nclass new_super: def __init__(self, type=None, object=None): if type is None: # super利用__class__组成闭包，这时__class__指向定义时所在的类，而不是运行时 # 在具体的实现中，__class__在编译时被写入闭包 if __class__ is None: raise RuntimeError(\u0026#34;super(): no arguments\u0026#34;) self.__type__ = __class__ else: self.__type__ = type self.__object__ = object def __get__(self, obj, type=None): # 如果没有指定第二个参数，可以用__get__方法来与obj绑定 if type is not None and self.__object__ is None: return new_super(self.__type__, obj) else: return self def __getattr__(self, attr): if isinstance(self.__object__, self.__type__): starttype = self.__object__.__class__ else: starttype = self.__object__ mro = iter(starttype.__mro__) for cls in mro: if cls is self.__type__: break for cls in mro: if attr in cls.__dict__: x = cls.__dict__[attr] if hasattr(x, \u0026#39;__get__\u0026#39;): x = x.__get__(self.__object__) return x raise AttributeError "},{"id":3,"href":"/posts/2020_annual_summary/","title":"2020 年终总结","section":"Posts","content":"2020一年，是在失望和痛苦中开始的，尽管我会认为失败会更加司空见惯，但是在当时看，还是不可接受的事。然后接下的一季，在家里度过了一段时间的neet生活，虽然可以拿新冠做理由，但是只是单纯的不想出门，这段时间大体上是用来找工作了，但其实做了一些其他的事来填充这段在家的时间。下半年在8月，经过一次偶然被邀请面试，再加上我自己急于脱离当前环境，放弃了接下去的求职，直接接了offer来到上海。冬季的我逐渐缓解了新租房和添置设备的经济压力，同时生活也开始变得规律稳定起来，这段时间几乎彻底放弃了学习，于是就这样延续到了我现在打字的时刻。\n第一季度 # 2020年的一月我刚结束了考研，对将来还有乐观的预想，在一月初，我的笔记本电脑的显卡不幸暴死了，我试图在不换主板的前提下修好它，但是由于需要一个芯片级的维修店，在市里搜寻失败之后，我决定在过年前一周左右送去淘宝寄修，这样顺利的话可以过年之前拿到。很不幸，预想完全是错误的。\n一月发生了众所周知的新冠病毒的广泛扩散和全国范围的大规模封锁，在我寄修电脑时，我虽然已经知道了这件事，并且先期屯了一盒口罩，但是却错估了这件事的持续时间和严重程度，以至于电脑在寄到维修店里的后几天，这家店由于所在小区出现了患者，导致整个店一直被封到3月。因此年初我都是在没有电脑的情况下度过的。\n一月比较幸运的事，我在月初几天考完了科四，成功拿到驾照，可以说是不幸中的万幸。\n二月初，封城宣传正是特别火热的时候，市里郊区一个村也用土堆上了进入的路。而我趁这段时间借接送父亲上班的时间顺便练车，每天绕一段路开车回家。这段时间开始在家里重读sicp，顺便看MIT 6.945 sicp的视频。另外值得一提的书是《谣言，世界最古老的传媒》,月初众多消息混杂着谣言，’辟谣‘这个字使用频率逐渐频繁，词义在不断滥用中变得模糊，而辟谣方对自己”权威“地位的滥用，也在快速消耗这个词的公众印象。\n谣言是对权威的一种返还。它揭露秘密，提出假设，迫使当局开口说话。同时，谣言还对当局作为唯一权威性信息来源的地位提出异议。 (p.16)\n二月末，得知了自己的考研成绩，在去年自己对数学的重点学习的努力下，分数终于达到了上一次考研的一半，而自己基本没有看的英语和政治反而继续得到了提高。如果用一个词来描述当时的情况，那即是“困窘”。我无从知道这样的原因，既没办法去想象，也不能回溯自己的记忆来找到原因。那么，然后怎么办？唯一可以肯定的是，在考研的科目中继续投入成本是不可接受的事，像操作系统之类的课程要继续深入需要扩展的阅读和亲手实现一个操作系统的行动，而不是对重复的内容继续重复，那么接下来要做的就是要开始着手找工作的事情。迫在眉睫的事则是，需要一个临时用的电脑。\n三月，用2000+临时买了配件准备组一台临时机器，而在没有电脑用的时候，我暂时在京东买了罗技k380，暂时接在pad上刷题。这段时间我还没有停下看sicp的事，至少这是临时的避难所，让我保持平静。\n三月虽然是春招开始的时间，但是因为疫情的形式，招人的公司减少了，而春招的时间也在延后。当时的我需要的是三部分的准备，首先要有一个完成度足够的项目来充实简历，然后对常问的八股文要有足够的准备，最后则是我看起来比较自信的方面：要刷一些算法题来保证可以过这一关。三月的我选择常见的简单起步的项目：一个flask的博客。\n选择flask是出于几个理由：1.语言方面我自己倾向于python，因为开发更快，而且在我有足够的基础知识下不会有太多的基础问题，另外是一点语言审美偏好。2.接下来就是django和flask二选一，我希望基础组件足够少，可以让我快速起步，结果很明显，是flask。\n三月末另外一件事是参加了被群友内推的银联笔试，过了之后约了4月初的面试，由于开发语言是java，所以需要准备些java八股文来过面试。\n三月另外同时做的事是写一个简单的python虚拟机，这起初是看了laike9m的博客，他在其中简单描述了python的block stack，并提到了byterun项目和项目的介绍文章，在我看了介绍之后，花了一些时间来写这个项目，简单写到单frame的求值过程。\n第二季度 # 4月，月初3天内看完了深入理解Java虚拟机， 把自己的flask项目勉强糊完，就直接开始了银联的面试，但其实面试并没有问的很深入，不过几个linux命令行的问题让我比较难受。4月中拿到了另一个群友公司的面试，约到了月底， 月底技术面也同样还算顺利，虽然是Clojure的公司，但是问的主要还是java，不过同样一般深入。\n这段时间，开始做java的准备，同时剑指的100道题也基本刷完，月底银联发了心理测评的邀请，形势看起来还算不错，月底开始看concurrent包的源码，aqs的内容和aqs设计论文让我学到很多，而当时我同时在twitter上Jiayuan的推荐下开始用roam research（当时使用者还很少），再加上打算更新一下博客，所以直接把aqs的笔记修整了一下搬到了博客上。就是这篇。\n博客以前使用的主题感觉有点审美过时，而同时不再支持我的中文标题。于是我把主题换到了现在这个样子。\n5月看起来一切都在正常发展，坏一点的事是我上个月过了技术面的公司，结果挂在了hr面，很难受。（之后这家公司开始了不加钱的995，看起来没去反而也许是好事）我也同时有闲情开始看一些别的技术书，同时更新了一下自己的byterun，开始支持函数调用之类的操作。同时接到了银联hr的谈薪电话，离offer只剩背调提交材料了。\n6月，继续更新了一点byterun，添加了class的支持，另外把包导入的python代码托给cpython直接调用，凑合成功推进了一点。下半月不巧才被通知我银联背调没过，因为我不是2020年毕业的应届生，这样我顿时又重新回到了3月多的境况，而且由于春招结束，情况更加恶劣起来。\n6月底，靠父亲的同乡提供了一个外包公司的职位，我自己并不想去外包，因为提升可能性很小，我打算靠以前的java八股文记忆继续找工作，接下来就需要一个java一套的项目，我选择了springboot+mybatis+mysql一套的rss订阅服务器，做的原因是当前的个人搭建rss服务基本只有tiny-tiny rss，这已经是2014年的项目，而且一直没有更新，我做这个感觉前景不错。\n在糊了不到一周之后基本可以完成靠rss链接或者导入opml文件订阅，接下来比较难受的地方在于一些提供商的rss并不能被roma解析，再加上我的工作效率一直保持在很低的水平，这个项目最终搁置在为我的现有功能添加api支持之后。\n6月底的其他时间重写了byterun，理了一下虚拟机结构，添加了不完整的code block。在试图解决class定义的一些问题时，发现想要继续下去，必须统一function和class及其他对象，应该像java一样使他们继承同一个基类，这样才能为以后添加一个gc提供基础。我对语言方面几乎没有了解，而不看《Inside The Python Virtual Machine》好像很难继续，所以同样搁置。\n6月临时码字开坑从0开始的python虚拟机，写了第一篇之后到现在还没继续写下去。\n第三季度 # 7月初，群友开坑qq机器人，正好碰到在玩公主链接，所以月初fork了一下，添加了切噜语翻译的功能玩票。几个月之后qq提供了官方收费机器人，并威胁了其他第三方机器人制作已经是后话了。\n7月在投了一些简历之后终于又约到了笔试，同时也有我现在的公司。7月主要在看《effective Java》，顺便给翻译提了一个pr。另外做的事是看了一些高性能mysql，做了些mysql文档优化这一节的翻译。\n7月初看了关于写一个web app框架的演讲之后，开坑看flask的源码，写了一些笔记。\n8月初把这些笔记写了新博客系列，flask的源码阅读。相对于常见的对行为的描写，我想更多体现做这些的思路，但是不幸自己对这方面的阅读不多，很难描述在架构选择的权衡。这个坑也因此搁置。\n8月初面试通过，然后快速和hr约了入职时间，鸽了之后的面试的同时也被对方公司鸽了。8月另外读的书是《对赌，信息不足时如何做出高明决策》中间几天都在找房子住。\n8月下半月是我刚开始入职的时候，抛去之前文章写的牢骚之外。工作中开始学写lua，perl和php。开始除了写一些爬虫之外，也基本没有什么事。时至今日，回顾我之前在每周总结的内容：\n爬虫从提供任务到入库的流程需要用crontab吗？我觉得还可以接受，在数据量现有的规模下，时间同步的方法批量处理数据不算是一个差选择\n信息传递需要用mysql吗？很显然太过重量级了。\nlua的正则还是一样的烦人，另外一个空内容的迭代器，现在看是可以理解的设计。\n9月基本没有做什么事，在进入下半年之后，没有学什么新内容，《A Philosophy of Software Design》看了大约1/3, 其他看的书是《遗落的南境》第一部，另外看了一部分《The Pragmatic Programer》\n9月听了捕蛇者说，在一期的结尾推荐里提到了q这个库，q的几个特性看起来比较有意思，所以去读了源码，写了博客。很不幸写完发现实现其实挺简单，这篇是彻底的水文，但我还是厚颜无耻的发了上去。\n第四季度 # 最后一个季度，也同样基本没有学什么东西。大略看了一半ddia，ddia作为今年继sicp之后看的第二流畅的技术书籍，整体阅读体验也比较愉悦，内容比较基础，最后还是欠下了一堆论文没有读。业余的其他时间，看了尼尔盖曼随笔集。\n12月尾，开坑一个github action项目，用ts来做，主要难度还是在于github的api和我本身没有学过ts，导致拖延十分严重，不小心拖到了下一年。\n结语 # 2020年结束的时候，总体心情重回平稳，至少不再像去年一样焦虑到四处开坑，从各个方面来说，都现在呆在一个平稳的境况下。遗憾的地方在于接下来想做的事太多，而到了必须要舍弃一部分的时候了。\n下一年，计划要做的三件事：\n读现有的几本关于数据库的书： ddia 数据库系统内幕 redis设计和实现 Kafka设计和实现 重读高性能mysql 该学rust了，重新来写我的虚拟机吧 [还没想好] 我先立个flag在这，说不定以后就不想做直接鸽了呢\n希望2021能做到每月一篇吧\n"},{"id":4,"href":"/posts/infinity_stream/","title":"Infinity stream","section":"Posts","content":"当我们在遍历一个列表时，我们很容易写出一个迭代式的遍历处理方式，就像常见的foreach语句一样，而通过使用流语句，在处理时可以将控制流程和数据流分离开来（至少是在形式上），形成了更加清晰的代码。\n一个常见的流式结构似乎是以下这样的：\nans = fib_iterator.stream() .filter(lambda x: True if x % 3 == 0 else False) .output(100) 其中fib_iterator是一个产生斐波那契数列的迭代器。 在这样的形式中，数据似乎由一个产生无穷的斐波那契数列的迭代器开始生成一条数据流，filter()在这条数据流上过滤掉所有使lambda返回False的值，并通过output()输出。\n简单的实现想法 # 在sicp中提到流式语法时，流可以被简单的描述为以下的样子\n(cons_stream (car_stream stream) next_promise) 流由两部分组成，前部分是已产生的值，而后半部分被表示为一个产生下一个值的承诺（promise），而promise会直到需要处理下一个值时才会被求值，在这里，假设产生下一个值的函数为：\n(def next x (+ x 1)) next_promise仅仅会返回一个用lambda包裹的next函数，而不对它做任何事，直到使用(stream_cdr stream)时，对它进行求值，生成(value, next_promise)。 这样，只要所有的将来的值是通过过去生成的值而产生的，那么这个流就会无限的延伸下去，从而在形式上生成了一个无穷的流，无论我们需要获取哪一部分的值，它总可以沿着这样的顺序生成出来。\n而在python中则很容易发现，iterator是这种语法的一个很好的体现。iterator需要实现两个方法__iter__()和__next__(),前者返回迭代器本身，而后者返回下一个值。在这里，__next__()函数可以看作延时求值的接口，当实现流式语法时，将需要调用流中下一个值时再执行__next__()，即可以达到延时调用的结果。\n更加深入一下iterator的实现，在python中的frame栈中可以修改frame的行为，只要__next__()函数在求值得到返回值之后不弹出frame栈，而是将其挂起，继续在栈的下一层工作，直到下一次调用__next__()函数时，继续__next__()函数的求值即可以做到这一点。想要实现这一点，那么就需要保存__next__()函数中的pc并且需要保存退出栈顶frame的原因信息了。（这一部分将在之后的文章提到codeblock_stack时详细讨论）\n整理一下想法，可以将stream有关的函数分为三个部分：\nstream() 这个函数用来构造一个流，构造材料需要是一个iterator，这样可以通过__next__()函数实现延时求值。 map(func), filter(func), each() 这些作为对数据流的每一个元素操作的函数，应该被实现为仅仅将输入函数注册到处理流程中，而不做其他的动作。 output(x) 这一类的函数实现最终的输出，在调用这个函数时，流才真正被求值，具体在output(x)中，希望会返回前x项，那么在x次的循环中，调用__next__()来获取流的基础输出，并在其上执行处理流程中的函数。 详细实现 # "},{"id":5,"href":"/posts/q_magic/","title":"Q's magic","section":"Posts","content":" 前言 # Q 是一个开源库，正如它介绍里所写的那样，它是用来“Quick and dirty debugging output for tired programmers.”，Q的用法主要有两种：\nimport q之后， 使用q(value)来 print value 的值，或是使用q/value， 或者q|value，只要在想 print 的值前加“q/”或“q|”的前缀，即可以print值\n在函数定义前加@q的修饰器,可以print 函数参数，返回值，运行时间等信息 本文用来展示q这个库是如何在300+行代码的篇幅下，完成这样的功能的。\nimport q之后为什么可以直接使用q()和@q # 想做到这件事的办法可以想到，如同其他语言一样q()需要被实现成一个全局的静态函数，在python中，则是在import时完成class q的实例化，那么另一个问题是，q 中 class 名是 Q ，那么调用应该是Q.q()，而不是q()，这部分的实现关键在于它将自己装载在了sys.module中,通过这条语句sys.modules['q'] = Q()并在class中实现__call__()函数，使得可以直接使用q()\nq/value如何实现 # q/value 修改一下格式就变为 q / value， 同时源码里也可以看到其中有__truediv__()函数，于是发现这里的实现在于 q 重载了/和|运算，使得这个运算符在执行了q print的操作之后返回__truediv__()的第二个参数。\nobject.truediv(self, other) 调用这些方法来实现二进制算术运算 (+, -, *, @, /, //, %, divmod(), pow(), **, \u0026laquo;, \u0026raquo;, \u0026amp;, ^, |)。例如，求表达式 x + y 的值，其中 x 是具有 add() 方法的类的一个实例，则会调用 x.add(y)。 python数据模型\n这里可以看到 q/value 时会调用 q 的__truediv__()函数，这样在 q 重载了这个函数的时候，达到了重载操作符的效果。\n@q如何实现 # q被调用时调用了__call__()函数，这个函数主要做了有关的几件事：self.inspect.getframeinfo(self.sys._getframe(1), context=9)通过getframeinfo()来获取调用附近的代码文本块，打印被修饰函数的基本信息，然后扫描文本块返回self.trace(), python 定义修饰器需要返回一个以修饰函数 func 为参数的 wapper 函数，那么可以想到 trace 里会返回 wapper，那么在这里，则是返回了self.functools.update_wrapper(wrapper, func)。\nfunctools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) 更新一个 wrapper 函数以使其类似于 wrapped 函数。 可选参数为指明原函数的哪些属性要直接被赋值给 wrapper 函数的匹配属性的元组，并且这些 wrapper 函数的属性将使用原函数的对应属性来更新。 此函数的主要目的是在 decorator 函数中用来包装被装饰的函数并返回包装器。 如果包装器函数未被更新，则被返回函数的元数据将反映包装器定义而不是原始函数定义，这通常没有什么用处。 module-functools\ntrace 里仅仅是定义了wapper(),而在wapper()中执行了 func，然后返回了 func 的返回值，在这里修饰器得到了 func 的参数，(q.__call__(self, *args),这里被作为修饰器调用时，args[0] 是被修饰的函数，这个参数被传到了 trace 里)因此可以遍历参数并 print 它们的值，func 在wapper 中执行，这样也可以 print 返回值\n在处理error时会有些麻烦，因为 func 是在 q 的wapper()中运行的，异常抛出时会抛到 wapper 的 栈帧，这里需要在 wapper 中获取 error 信息，这是通过 self.sys.exc_info()来做到的，通过 print error_trace_back.tb_next 可以正确显示异常。\nreference # https://github.com/zestyping/q http://pyvideo.org/video/1858/sunday-evening-lightning-talks#t=25m15s "},{"id":6,"href":"/posts/weekly_report_20200907_20200913/","title":"2020.09.07-2020.09.13","section":"Posts","content":" 2020.08.31 - 2020.09.06 # 上周总结 # 重写虚拟机，开始做了一部分，试图要做的部分比想象的要多很多，基本上所有的类都要重新设计，看起来不是一周可以完成的工作量 A Philosophy of software design，没有读。上周在读《对赌》大概读了一半。 Ts，要做的大概是vscode的插件，或者是为web框架贡献些代码。 上周游戏时间10+小时，主要都在啃臭，这游戏实在是玩的太过于昏睡，丢箱子模拟器太无聊了，普通难度甚至是一种折磨，急需调到简单难度看剧情。买了新锅用来煎牛排，效果相当不错，配合上温度计现在可以达到不完美的五分熟，味道十分让我满意。买了小米屏幕挂灯，效果也基本上不错，仅仅是为了适用于我的显示器做了一些改造。\n下周 # 下周继续三件事：\n重写虚拟机，这部分需要继续读一下read insider the python virtual machine，本周的目标是添加pyobject类，让function和class继承。 A Philosophy of software design， 现在是读到5.5，至少这周要读完11章。 写些js，先把roam research的自动文本模板脚本修改到可用的地步 观点 # 标准化自己的工作流并没有为自己带来更多的限制，而是带来了更多的自由。标准化自己的工作流，方法的关键在于对自己行为的划分需要更加粗粒的密度，并不需要以分钟为单位来规范自己的时间，也不需要规范自己的每一行的文字格式，而是对于自己的任务和内容初步划分做格式化的规范，像设置MIT3(most important thing)和像现在这样为每周总结划分栏目的方式，可以使自己快速进入输出内容的状态，不需要花费大量时间思考内容方向。而在每个栏目内的自由发挥，则可以为自己带来更加自由的输出方式。划分任务，而不是时间；划分内容，而不是形式\n杂谈 # END\n"},{"id":7,"href":"/posts/weekly_report_20200831_20200906/","title":"2020.08.31-2020.09.06","section":"Posts","content":" 2020.08.31 - 2020.09.06 # 上周总结 # 上周计划的三件事：\nTs ts入门写了hello，world，依然没有找到什么项目可以做，考虑写一下vscode的扩展，或者在github上找一个吧。\n重写虚拟机的任务根本没动，这周其实什么也没有干。\nA Philosophy of software design， 书读了半章，进度缓慢。\n上周游戏时间13小时，基本不算高的。大量的休息时间主要用来做饭和做些杂事了，上周买了新的人体工学椅和键盘。阿米洛的静电容轴响应力度足够小，回弹也快速，而且基本上没有误触，大键的手感没有小键好，樱花粉轴整体上还是比较满意的。人体工学椅买了金卓b，不过到现在还没有找到比较好的坐法，感觉100度的椅角度比较好，但是并没有这一档，不固定椅背可能能达到效果，但是不知道这种方法有没有什么坏处。\n下周 # 下周继续三件事：\n重写虚拟机， 这件事作为这个项目的第一阶段目标，还是应该要做完的，至于之后继续的发展，要看我以后会不会有继续这个方向的学习计划。 A Philosophy of software design， 现在是读到5.5，至少这周要读完11章。 Ts， 对于前端能做到什么程度我还没有清晰的概念，先github逛一下吧。找个项目，目标大概到提出一个pr。（可能完不成 观点 # 相对于notion这样以主题为核心来记录笔记的方法十分适合读书或者其他的笔记整理，而roam research这样的自下而上的笔记方法在记录自己偶发的想法的时候会更加方便，使用链接和tag会更好的整理想法，建立一个单独的页面可以用来存放和分类，在这个角度来看，roam research更加适合与个人的笔记系统。 一个简单的获取信息的筛选系统：1.以输出知识为卖点的账号，如果达到日更新，那么即可以说这些账号的输出都是垃圾（除非是多人合作的方法，而其中每个作者输出频率不高于一周一篇）。2.新闻及其他资讯应该在周的尺度上观看，如果你不是依靠短暂的市场信息来获利的话，任何的日为单位的咨讯对你来说都是可有可无占用时间的垃圾，这些东西除了谈资之外毫无作用，反而会带来获取到什么的错觉。（一个参考观点：对最近事件即时性的解释基本都是错误的，无法用来预测任何事） 杂谈 # 上周提到自己测试的时候经常被block，最终发现其实是user agent的问题，可能是一直沿用的user agent版本太低，更新之后基本就不出现这样的问题了。公司的爬虫脚本居然是要一个个部署到集群上的，而不是靠一个控制系统调用，个人感觉十分原始。而其他的java数据处理程序居然也是类似效果，靠bat文件+参数分别启动，可能有热替换的好处，但是java热更新应该是可用的解决方案，总之感觉比较原始。\n人体工学椅感觉很难靠自重把椅背压下去，导致整个椅子在感觉上存在感很强，感觉不是什么好事，可能要继续调整下，这把椅子头枕位置需要多2厘米才能支撑到脖子，是特别的败笔。\n用在食物上的花费没有想象中高，大概估计一月花1500左右，感觉一个月至少需要填入500左右的花费更好一点，发了工资去买煎锅和牛排吧。\n本周基本没读什么，导致blog也写不出来什么内容，下周打算在这周的栏目上添加一些，周总结大概长度达到2000字可能会比较好。\nEND\n"},{"id":8,"href":"/posts/weekly_report/","title":"2020.08.24-2020.08.30","section":"Posts","content":" 2020.08.24-2020.08.30 # 新工作 # 这个月在经过了短暂的找工作时间之后，光速接了新的offer，拿到了钱并没有多少，但是工作压力并不大的新工作，结束了我在今年的半年neet生活。neet其实并没有那么令人厌恶，让人痛苦的是在家里深受限制，由于没有工作，不能看更多在长远有好处又感兴趣的书，只能一遍一遍刷翻过的面试博客，网络上的面试文章有很多错误之处，但同时一些错误的说法才是可以通过面试的答案，看着十分痛苦，另外这些没什么联系又内容十分多的东西，即使被称为知识也十分可疑。刷题反而成了我为数不多的逃避时间。\n但是新公司面试十分简单和原始，一时间在我准备了挺久的python面试的情况下有点措不及防，关于html的几个问题我一概不知，在写html的时候我基本上是没有文档无法独立完成工作，没想到在这方面还有要求。\n本以为是作为写python被招进来的，没想到主要工作是维护php的网站和写爬虫，公司的爬虫使用的语言挺多，方法反而感觉原始，即使是Java项目，也是基本上脚本模式存在，依靠一个php程序调用.在文件里居然有多个脚本复用同样的300+行代码，居然没有抽象成Util工具；主方法长到让人难受，基本上没有什么封装；代码风格十分诡异，一部分继承与其他地方的变量名，导致和语言常用的命名格式有区别，另一部分在于分行基本不存在，一行长达300+字符简直是首次见到，代码块之间基本没有分割，感觉就像拉长的蚯蚓，让人看着十分痛苦。\n这两周做的事情基本是在维护修改继承的Lua爬虫，有技术含量的事基本都被人做过了，http请求全靠curl，用了通用格式的正则方法而不是lua自己的string.match()让人高兴，其他也没有什么有兴趣的事情，由于自己没有生成cookie的脚本，所以在测试时经常被block，看来考虑写一个需要被提上日程。\nps.公司项目基本没有测试，我十分好奇为什么这样测试代码还没有我项目长的东西可以成功跑这么多年，话说爬虫测试也基本很难做，基本只能做一下格式测试，对内容似乎没有什么好办法。\npss.Lua语法很让人难受，无内容的迭代器居然是自己返回，既没有抛error也没有任何返回就能退出让人十分恶心\n搬家 # 花了大量的钱用来整租了一套一室户，至少有干净的厕所和厨房令人心情愉快，房东夫妇也看起来很好，成功办了居住证，感觉不久后至少可以拿住房公积金分担点压力，总之本来工资也没多少，这一年能攒一个房租钱就不错了。\n一个人住有挺多好处，自己做饭还是不错的，不过最近做饭时间确实挺长，基本每餐要一个小时，虽然味道不错，但是占用还是挺多。\n超市东西还不错，有盒马的补充基本就可以当地解决，不至于求助于淘宝，最近一周食物差不多要花200+，其中一大半是买肉的钱，摆脱了家里高碳水的生活，现在可以一餐吃至少半斤各种的肉，还是让人愉快。\n发工资之后应该买个铸铁煎锅，可以用来煎牛排了。最近看人牛排视频十分嘴馋，先买些50多一斤的来试试吧。\n一个人的另一个好处是基本可以无限外放，24小时开着电脑了，但是显示器的hdmi线似乎是有什么bug，自动熄屏之后有时不能自动恢复，十分难受，另一个问题是桌子本身挺小，以后可能很难同时拼高达和干别的事，另外全尺寸键盘有点太长，我基本不会利用数字小键盘，想换一个键盘，目前犹豫一下ikbc和大f。\nps.椅子坐着没有头部支撑有点难受，发工资了买新椅子吧。(下周就买算了)\n上周总结 # 上周的空闲时间基本上都在睡觉和玩游戏，游戏其实也没多玩，感觉恢复的时间基本上差不多了，每天保证睡眠还是挺重要。\n自己的github也没有维护，是全白，连评论也没回。\n下周 # 按惯例，下周主要搞三件事：\n学TS， 我要开始学Ts了，不知道有什么项目可以做，先两天入门试试吧 重写虚拟机，python虚拟机设计虽然是垃圾，但还是至少自己的先重写，重理一下。先支持基本功能再去看别的实现吧。(感觉接下来一年搞分布式数据库可能是是收益最大的方向，先试着做做看吧)(blog预定，从零开始的python虚拟机第二篇，打算写控制流程和code block) 读书：A Philosophy of Software Design, 看了一周了，感觉至少要两周看完，先看着呗。(下本书预定：数据库系统内幕) 杂谈 # 想搞日常直播，但是感觉也很难有人看，不知道能不能搞起来。\n想买面包机，但是现在每周面包花费也就10+，基本不是很划算。\n需要屏幕挂灯和新椅子，买个人体工学椅吧。\n想要女朋友\nEND\n"},{"id":9,"href":"/posts/read_flask_source_code_1/","title":"Flask 源码阅读（1） : request的处理流程","section":"Posts","content":" 前言 # 本系列试图从flask 1.0版开始阅读一个完整的项目，不同于常见的追踪启动后行为来阅读源码的方式，这一个系列的文章打算从写一个符合wsgi方式的web框架开始，然后逐步完善添加功能的方式来写阅读笔记。\nwsgi规范 # def app(environ, start_response): start_response(\u0026#39;200 OK\u0026#39;, [(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/plain\u0026#39;)]) yield \u0026#34;Hello world!\\n\u0026#34; 一个简单的 wsgi 规范的 app 会被构建为以上的形式。其中app作为即将扩展的部分，需要被实现为一个 Callable 对象，它接受 environ 和 start_response 两个参数，并返回一个字节序列。\nflask 的app实现 # 以上提到 app 需要被实现为一个 callable 对象，那么，作为主体的 Flask 类则要定义 __call__() 函数。\ndef __call__(self, environ, start_response): return self.wsgi_app(environ, start_response) 可以看到__call__ 函数其实只是返回了wsgi_app(environ, start_response)， 真正的app主体在 wsgi_app上，__call__() 只是它的一个包装。通过这种方式可以分离 app 方法，便于对 app 进行修改。\n观察wsgi_app() 方法\ndef wsgi_app(self, environ, start_response): ctx = self.request_context(environ) error = None try: try: ctx.push() response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) 方法主体十分简单，首先根据 environ 构造 context ， 然后通过 full_dispatch_request() 解析请求返回函数 response ，response(environ, start_response) 函数返回真正需要获得的字节序列。\nrequest_context() 函数 # def request_context(self, environ): return RequestContext(self, environ) 返回了 RequestContext 类， 暂且跳过。\nfull_dispatch_request() 函数 # def full_dispatch_request(self): self.try_trigger_before_first_request_functions() try: request_started.send(self) rv = self.preprocess_request() if rv is None: rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) 如上所说，full_dispatch_request() 函数作为主体主要执行了以下几件事\ntry_trigger_before_first_request_functions() : 这个函数并不复杂，简单来说是在第一个 request 之前初始化并依次执行self.before_first_request_funcs中的函数。\nrequest_started.send(self) : 这一部分request_started作为_FakeSingnal对象用来发送 request start的信号\npreprocess_request() : 预处理请求，先由上下文栈弹出蓝图，调用url_value_preprocessors.get(none， ())来获取针对所有 url 值需要的函数，如果有针对所有 url 都起作用的视图函数，则在此调用。接下来调用每一个使用before_request装饰的可作用于所有 request 的函数。如果其中某一个函数返回一个值，这个值将会作为视图返回值 处理并停止进一步的请求处理。\ndispatch_request() ：本函数进行url匹配，返回视图函数返回值。由栈顶弹出 request，然后rule = req.url_rul，如果 rule 含有 provide_automatic_options，自动调用self.make_default_options_response()函数并返回。否则返回self.view_functions[rule.endpoint] (**req.view_args)，可以看出这里仅通过endpoint来匹配 view function 字典。\nfinalize_request() : 这个函数将先调用make_response(rv)视图返回值转变为真正的 response (这一部分之后再谈)。接下来是函数主要部分，process_response(response)函数获取上下文，获得蓝图和上下文中 request 之后需要调用的函数，接下来构造执行链 ctx.after_request_functions-\u0026gt;（逆置）bp.after_request_functions-\u0026gt;适用于所有的 request 的 （逆置） after_request_functions。按照执行链依次执行，最终储存session，结束request。\n小结 # 本文作为 flask 源码阅读的第一篇，简略的浏览了一遍 app 中关于 request 的处理流程，设计方式基本十分直观，主体分为三部分，在 request 之前，request 处理， request 之后构建了相关的执行链，并进行调用。 接下来一篇将试图观察视图函数的注册以及 route 部分的实现。\n"},{"id":10,"href":"/posts/from_zero_to_a_python_interpreter_1/","title":"从零开始的python解释器（1）","section":"Posts","content":" 单条字节码的解释运行 # 反编译字节码 # python 字节码形式可以用dis.dis()来反编译code object来获得，先考虑一段简单的python代码:\na = 1 b = a + 1 反编译之后是： 可见字节码拥有2Byte长度，前半部分用来标识字节码，后半是参数。其中字节码的参数仅用来标识字节码参数的位置，而不是参数本身。\n字节码来源 # code object是由compile()函数编译代码字符串生成的。在当前要进行的部分暂时关注它的一部分内容：\ncode.co_code = b\u0026#39;d\\x00Z\\x00e\\x00d\\x00\\x17\\x00Z\\x01d\\x01S\\x00\u0026#39; code.co_consts = (1, None) code.co_names = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) 以上则是解释运行暂时需要的全部材料，其中co_code则是python字节码，co_consts用来存储需要的常数，co_names存储需要的变量。\n举例：LOAD_CONST的解释 print(co_code[0])则会返回100，即是字节码， co_code[1]= 0则是字节码参数 通过dis.opname[100]则可知道字节码opname = LOAD_CONST,参数则是co_consts[0] = 1。这样第一条字节码就可以翻译为LOAD_CONST(1)\n字节码执行 # 由上知道了字节码本身被翻译为LOAD_CONST(1)，接下来就需要执行该函数 python vm与JVM相同，都是基于操作数栈的解释器，函数在执行后将返回值压入操作数栈 因此，LOAD_CONST()函数可以被写成以下形式\ndef LOAD_CONST(num): stack.push(num) 这样，第一条字节码便执行完成\n多条字节码顺序执行 # 这样可以写出字节码解释器主体的循环：\npc = 0 stack = [] def run(): while True: byteName, arguments = prase_byte_code_and_argument() dispatch(byteName, arguments) if byteName = \u0026#34;RETURE_VALUE\u0026#34;: return 此处，鉴于将来要对于循环和分支结构的支持，考虑通过判断RETURE_VALUE来返回退出循环。\nprase_byte_code_and_argument()函数 # 本函数用来解析code.co_code的字节码，转换为字节码函数名和参数。\ndef prase_byte_code_and_argument():\rbyteCode = code.co_code[pc]\rbyteName = dis.opname[byteCode]\rarguments = []\rpc += 2\rif byteCode \u0026gt;= dis.HAVE_ARGUMENT:\rarg = code.co_code[pc-1]\rif byteCode in dis.hasconst: # Look up a constant\rarg = code.co_consts[arg]\relif byteCode in dis.hasname: # Look up a name\rarg = code.co_names[arg]\relif byteCode in dis.haslocal: # Look up a local name\rarg = code.co_varnames[arg]\relif byteCode in dis.hasjrel: # Calculate a relative jump\rarg = pc + arg\relse:\rarg = arg\rarguments = [arg]\relse:\rarguments = []\rreturn byteName, arguments dispatch(byteName, arguments)函数 # 获取到byteName之后要得到对应的函数对象，此时使用getattr(byteName)来获取对应的函数对象 然后调用byteName(*arguments)完成执行\ndef dispatch(byteName, arguments): func = getattr(vm, byteName) func(*arguments) RETURE_VALUE # return value暂时仅作为字节码的终止，因此判断运行到此处时退出主循环。\n总结 # 最简单的字节码求值器的主题就这样写成了，剩余的其他工作即是填充上未写过的字节码函数定义，这样字节码的解释求值即可以完成了。\n"},{"id":11,"href":"/posts/juc_aqs/","title":"JUC包AQS设计","section":"Posts","content":" 为什么需要AQS JUC包中提供了一系列的同步器，这些同步器都有以下基本功能 内部同步状态的管理 内部同步状态的设置 使一个线程被阻塞 使线程被其他线程唤醒 几乎任何一个同步器都可以用来设计其他的同步器，因此将共有部分抽象并设计框架成为一个符合直觉的需求 AQS设计需求 功能目标 基本方法，Acquire和Release 阻塞和非阻塞操作 可选的超时设置 通过中断实现的任务取消，通常是分为两个版本，一个 acquire 可取消，而另一个不可以 独占与非独占模式 监控形式的await/signal 操作 性能目标 AQS结构 acquire和release while (synchronization state does not allow acquire) {\renqueue current thread if not already queued;\rpossibly block current thread;\r}\rdequeue current thread if it was queued; update synchronization state;\rif (state may permit a blocked thread to acquire)\runblock one or more queued threads; 同步状态的原子性管理 AQS使用了一个32位int保存state，并提供getState, setState, 和compareAndSet来读取和操作 在CyclingBarrier中使用了64位state， 因此利用了锁来完成原子性操作 线程的阻塞与解除阻塞 通过JUCLockSupport park和unpark来控制阻塞和feizuse park是基于线程设置的，而不是基于同步器 unpark是没有计数的，因此可能有多余的unpark附在线程上 队列的管理 阻塞队列采用严格的FIFO链表队列，使用了变体的CLH锁。 为解决取消和超时功能，待选MCS锁变体 节点通过自旋和CAS操作插入，每个节点状态被保存在它的前驱，因此自旋阻塞类似while(node.pred.state != release); CLH锁的优点在于节点的入队与出队总是快速， 无障碍且无锁的，而且由于每个节点的状态保持在前驱，使得修改节点可以分散进行； 一个节点的前驱修改其状态，他的后继在下一次自旋时即会发现状态的改变，在阻塞队列中，则需要前驱节点去显式的唤醒（即unpark。 其中节点的next的仅为一种优化，这个队列是由prev所链接的，由于缺少应用于双向列表的CAS操作，next仅仅是直接赋值的。因此在唤醒时使用next来找到需要唤醒的节点，next不存在也并不能证明后继不存在，需要由tail前溯来确认。 节点在前驱中的状态是用于控制阻塞而不是自旋，在同步器中，线程仅在tryAcquire返回true时才在acquire返回。 活动线程在队首时，仅允许tryAcquire来获取锁，也可能Acquire失败而重新堵塞，此时是通过检查前驱是否为head来确认解除许可。取消状态也必须在状态位实现，因此单bit的release位并不够。 设置状态同时可以避免多余的park和unpark，在线程park前，设置signal位并检查同步状态和节点状态。线程release时重置状态，这样显性的标识状态可以避免多次阻塞及引入多次冲突的开销。 Acquire操作 if (!tryAcquire(arg)) {\rnode = create and enqueue new node;\rpred = node\u0026#39;s effective predecessor;\rwhile (pred is not head node || !tryAcquire(arg)) {\rif (pred\u0026#39;s signal bit is set)\rpark();\relse\rcompareAndSet pred\u0026#39;s signal bit to true;\rpred = node\u0026#39;s effective predecessor;\r}\rhead = node;\r} release if (tryRelease(arg) \u0026amp;\u0026amp; head node\u0026#39;s signal bit is set) {\rcompareAndSet head\u0026#39;s signal bit to false;\runpark head\u0026#39;s successor, if one exists\r} 条件队列 #TODO AQS使用 AQS作为模板提供给子类，子类仅需要设置更新状态。在JUC包中的同步器使用了一个内部类来包装AQS，重写了tryAquire和tryRelease来控制同步。 AQS提供了多个版本的Aquire和Release，包括超时和中断版本。并提供了tryAcquireShared来控制可重入的资源，方法通过返回值通知框架所剩资源状况，在release时框架通过级联来唤醒多个节点。 公平与非公平功能： 在一些条件下，非公平的获取锁可以有效提高同步器吞吐量，而如果外来线程可以持续抢占锁则会造成队列中线程饥饿。 FIFO队列在进入之前线程会调用tryAcquire方法，因此获得了一个与队头线程竞争的机会，从而可以实现公平与非公平的竞争，此时可以修改tryAcquire中对资源的请求次数来使其偏向外来线程；如果要实现严格的公平竞争，则可以通过添加约束，使线程只有入队才能调用tryAcquire。 一个比完全公平竞争优化的方法：在lock队列为空时，线程可以使用tryAcquire来获取锁，这样有一个线程可以不必入队获取到锁，得到性能的一点优化。 Reference http://gee.cs.oswego.edu/dl/papers/aqs.pdf https://www.inoreader.com/article/3a9c6e78f01cc939-juc-aqs "},{"id":12,"href":"/posts/process_and_thread/","title":"进程与线程","section":"Posts","content":" 进程 # 1.进程是什么？ # 一个进程是一个正在执行的程序的实例。一个进程是一种类型的活动，它包含程序，输入，输出以及状态。单个处理器可以被多个进程共享，处理器在多个进程间快切换，以达到（伪）并行的效果，这种形式被称为多道程序设计。\n2.进程的创建 # 进程在以下四种情况下可以被创建：1.系统初始化 2.在执行的进程执行了创建进程的系统调用 3.用户请求创建进程 4.批处理作业初始化。\n在unix系统中只允许通过fork创建新的进程，创建的子进程通过执行execve系统调用来执行一个新程序。之所以使用两步等等系统调用，是因为要在fork和execve之间由进程完成对标准输入输出和标准错误文件的重定向。uinx的子进程的地址空间是父进程的一个副本，两者共享不可修改的内存，或者子进程通过写时复制共享父进程的所有内存。\n在Windows中，父进程调用CreatProcess来处理进程创建，执行新程序。\n3.进程的终止 # 进程由四种原因终止：1.正常退出（自愿）2.出错退出（自愿）3.严重出错（非自愿）4.被其他进程杀死（非自愿）\n4.进程的层次 # 在unix中进程和子进程及其后裔进程构成进程组，信号被传给进程组的所有进程，进程组的各进程自主决定是否响应信号。 在windows中进程的层次彼此是相同的，父进程通过句柄来控制子进程，但是其可以把句柄传送给其他进程。\n5.进程的状态 # 进程分为运行态，就绪态，阻塞态。 运行态的进程如被操作系统发现无法继续，如需要等待输入转换成阻塞态。阻塞态的进程在得到输入时就转换为就绪态。就绪态的进程和运行态的进程由调度系统调度可以互相转换。 进程不能由阻塞态直接转换为运行态，进程在阻塞态下获得资源后会先达到就绪态。同样，进程不能由就绪态转换为阻塞态，就绪态的进程并不在运行中，不能通过操作失去拥有的I/O资源。\n6.进程的实现 # 为实现进程，需要在操作系统中维持一个进程表，每个进程占用一个表项。进程表项包含进程状态的重要信息，包括程序计数器，堆栈指针，内存分配状况，文件状态，账号和调度信息，及其他在调度时和转换为阻塞态时需要保存的信息。 中断发生时：1.硬件将程序计数器保存入堆栈 2.硬件由中断向量装入新的程序计数器 3.通过汇编程序保存寄存器值 4.汇编程序设置新的堆栈 5.执行中断服务程序 6.调度程序决定下一个运行的进程 7.C过程转移控制到汇编代码，装入新的程序计数器及其内存映射开始新的进程\n"},{"id":13,"href":"/posts/effecient_method_of_scotty/","title":"斯科特杨的高效率方法","section":"Posts","content":"在阅读了Scoltt Yang的几本关于高效率的书之后，总结并试着运用了一些关于高效率的方法，在这里做一些总结。\n日/周目标清单 # 建立一个周目标清单，并在每天开始的时候将清单中的一些任务添加到日目标清单中。\n每天日目标清单中的主要工作应该不超过3个，可以让你分配主要的精力在这些任务上面。（这条原则来自于《精力管理》）\n在做完清单中的所有项之后立刻开始休息，即使你仅使用了3个小时就完成了今天的任务，也要避免继续添加今天的任务，正如我们在小时候会有即使做完作业也会被父母继续添加任务这样的经历，我们应当避免把日目标清单变成普通的todo-list，从而减少每天完成任务的动力。\n每周工作六天，在每周的最后一天不要设置任何需要大量精力的任务，为自己思考休息提供充足的空闲，给自己干涸的电池充满电。\n精力管理 # 我们在工作时应当管理的是我们的精力和任务，而非时间。\n安排你的食物，少食多餐，每天吃4-6餐。\n工作90-120分钟休息一次，注意力是消耗品，同时也需要锻炼。\n将每天固定要做的事建立为习惯，让这些事自动完成。\n做自己想要去做的事，而不是应该去做的事。\n建立习惯 # 30天建立一个习惯，并将它写在纸上或者以文档记录下来，在最初的30天之内，一旦在某一天停止就重新开始计数，重新坚持30天。 之后便可以不必坚持的如此严格，身体会自动将它完成。\n选择要建立的习惯时推荐阅读《Zen to do》\n批处理 # 生活中有大量的事情可以使用批处理来解决，把大量原本填充到其他空余时间的事情集中解决，从而可以节省出大量额外的时间。\n以下几类事情可以使用批处理的办法来解决：\n阅读 集中阅读订阅的博客或者文章，每日学习工作中的阅读任务也可以批处理来解决。 邮件处理/拨打电话/社会联系 作业/写博客/电脑工作 一次性做这些工作可能会花费大量的时间，但是可以避免每天进入专注时花费的时间，也不必使自己承受拖延的痛苦。 清扫/购物 将家务之类的事务在每周的某一天集中完成，可以避免陷入无尽的家务漩涡。 思考/设置目标 在周日把自己的项目或者一些任务放入自己的周清单，使用完整的一块时间来进行计划，远比使用小段时间计划要好。 "},{"id":14,"href":"/about/","title":"About","section":"","content":"我是b1indsight， 这是我的twitter。\nabout还没写，我好懒\n"}]